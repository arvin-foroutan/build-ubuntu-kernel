From b8a2fa163567a9cd7fb92fd9928aafeeeabb96bf Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@natalenko.name>
Date: Sun, 19 Sep 2021 15:26:57 +0200
Subject: [PATCH 14/14] lrng-5.14: update to v42

Signed-off-by: Oleksandr Natalenko <oleksandr@natalenko.name>
---
 crypto/jitterentropy.c                        |  29 --
 drivers/char/lrng/Kconfig                     |   8 +
 drivers/char/lrng/Makefile                    |   8 +-
 drivers/char/lrng/lrng_chacha20.h             |   6 +-
 drivers/char/lrng/lrng_drng.c                 |  52 ++-
 ...lrng_archrandom.c => lrng_es_archrandom.c} |   0
 drivers/char/lrng/lrng_es_aux.c               | 274 +++++++++++++++
 .../lrng/{lrng_sw_noise.c => lrng_es_irq.c}   | 108 +++++-
 .../lrng/{lrng_sw_noise.h => lrng_es_irq.h}   |   0
 .../char/lrng/{lrng_jent.c => lrng_es_jent.c} |   4 +-
 .../char/lrng/{lrng_pool.c => lrng_es_mgr.c}  | 315 ++----------------
 drivers/char/lrng/lrng_internal.h             |  87 +++--
 drivers/char/lrng/lrng_proc.c                 |   2 +-
 drivers/char/lrng/lrng_selftest.c             |  20 +-
 drivers/char/lrng/lrng_switch.c               |  15 +-
 include/crypto/internal/jitterentropy.h       |   3 -
 16 files changed, 540 insertions(+), 391 deletions(-)
 rename drivers/char/lrng/{lrng_archrandom.c => lrng_es_archrandom.c} (100%)
 create mode 100644 drivers/char/lrng/lrng_es_aux.c
 rename drivers/char/lrng/{lrng_sw_noise.c => lrng_es_irq.c} (89%)
 rename drivers/char/lrng/{lrng_sw_noise.h => lrng_es_irq.h} (100%)
 rename drivers/char/lrng/{lrng_jent.c => lrng_es_jent.c} (96%)
 rename drivers/char/lrng/{lrng_pool.c => lrng_es_mgr.c} (52%)

diff --git a/crypto/jitterentropy.c b/crypto/jitterentropy.c
index ca7e70dab..f36a39131 100644
--- a/crypto/jitterentropy.c
+++ b/crypto/jitterentropy.c
@@ -854,32 +854,3 @@ int jent_entropy_init(void)
 
 	return 0;
 }
-
-struct rand_data *jent_lrng_entropy_collector(void)
-{
-	static unsigned char lrng_jent_mem[JENT_MEMORY_SIZE];
-	static struct rand_data lrng_jent_state = {
-		.data		= 0,
-		.old_data	= 0,
-		.prev_time	= 0,
-		.last_delta	= 0,
-		.last_delta2	= 0,
-		.osr		= 1,
-		.mem		= lrng_jent_mem,
-		.memlocation	= 0,
-		.memblocks	= JENT_MEMORY_BLOCKSIZE,
-		.memblocksize	= JENT_MEMORY_BLOCKS,
-		.memaccessloops	= JENT_MEMORY_ACCESSLOOPS,
-		.rct_count	= 0,
-		.apt_observations = 0,
-		.apt_count	= 0,
-		.apt_base	= 0,
-		.apt_base_set	= 0,
-		.health_failure = 0
-	};
-
-	if (jent_entropy_init())
-		return NULL;
-
-	return &lrng_jent_state;
-}
diff --git a/drivers/char/lrng/Kconfig b/drivers/char/lrng/Kconfig
index 0c654f4db..de50abaf5 100644
--- a/drivers/char/lrng/Kconfig
+++ b/drivers/char/lrng/Kconfig
@@ -480,6 +480,14 @@ config LRNG_RUNTIME_ES_CONFIG
 	  lrng_jent.jitterrng for the Jitter RNG entropy source, and
 	  lrng_sw_noise.irq_entropy for the interrupt entropy source.
 
+config LRNG_RUNTIME_MAX_WO_RESEED_CONFIG
+	bool "Enable runtime configuration of max reseed threshold"
+	help
+	  When enabling this option, the LRNG provides an interface
+	  allowing the setting of the maximum number of DRNG generate
+	  operations without a reseed that has full entropy. The
+	  interface is lrng_drng.max_wo_reseed.
+
 config LRNG_TESTING
 	bool
 	default y if (LRNG_RAW_HIRES_ENTROPY || LRNG_RAW_JIFFIES_ENTROPY ||LRNG_RAW_IRQ_ENTROPY || LRNG_RAW_IRQFLAGS_ENTROPY || LRNG_RAW_RETIP_ENTROPY || LRNG_RAW_REGS_ENTROPY || LRNG_RAW_ARRAY || LRNG_IRQ_PERF || LRNG_ACVT_HASH)
diff --git a/drivers/char/lrng/Makefile b/drivers/char/lrng/Makefile
index a633638af..623813764 100644
--- a/drivers/char/lrng/Makefile
+++ b/drivers/char/lrng/Makefile
@@ -3,10 +3,10 @@
 # Makefile for the Linux Random Number Generator.
 #
 
-obj-y				+= lrng_pool.o lrng_aux.o \
-				   lrng_sw_noise.o lrng_archrandom.o \
+obj-y				+= lrng_es_mgr.o lrng_aux.o \
+				   lrng_es_irq.o lrng_es_archrandom.o \
 				   lrng_drng.o lrng_chacha20.o \
-				   lrng_interfaces.o
+				   lrng_interfaces.o lrng_es_aux.o
 
 obj-$(CONFIG_NUMA)		+= lrng_numa.o
 obj-$(CONFIG_SYSCTL)		+= lrng_proc.o
@@ -14,7 +14,7 @@ obj-$(CONFIG_LRNG_DRNG_SWITCH)	+= lrng_switch.o
 obj-$(CONFIG_LRNG_KCAPI_HASH)	+= lrng_kcapi_hash.o
 obj-$(CONFIG_LRNG_DRBG)		+= lrng_drbg.o
 obj-$(CONFIG_LRNG_KCAPI)	+= lrng_kcapi.o
-obj-$(CONFIG_LRNG_JENT)		+= lrng_jent.o
+obj-$(CONFIG_LRNG_JENT)		+= lrng_es_jent.o
 obj-$(CONFIG_LRNG_HEALTH_TESTS)	+= lrng_health.o
 obj-$(CONFIG_LRNG_TESTING)	+= lrng_testing.o
 obj-$(CONFIG_LRNG_SELFTEST)	+= lrng_selftest.o
diff --git a/drivers/char/lrng/lrng_chacha20.h b/drivers/char/lrng/lrng_chacha20.h
index 87361f26b..bd0c0bee3 100644
--- a/drivers/char/lrng/lrng_chacha20.h
+++ b/drivers/char/lrng/lrng_chacha20.h
@@ -21,9 +21,5 @@ struct chacha20_block {
 
 static inline void lrng_cc20_init_rfc7539(struct chacha20_block *chacha20)
 {
-	/* String "expand 32-byte k" */
-	chacha20->constants[0] = 0x61707865;
-	chacha20->constants[1] = 0x3320646e;
-	chacha20->constants[2] = 0x79622d32;
-	chacha20->constants[3] = 0x6b206574;
+	chacha_init_consts(chacha20->constants);
 }
diff --git a/drivers/char/lrng/lrng_drng.c b/drivers/char/lrng/lrng_drng.c
index 480a529fd..701fb26c6 100644
--- a/drivers/char/lrng/lrng_drng.c
+++ b/drivers/char/lrng/lrng_drng.c
@@ -49,6 +49,13 @@ static struct lrng_drng lrng_drng_atomic = {
 	.hash_lock	= __RW_LOCK_UNLOCKED(lrng_drng_atomic.hash_lock)
 };
 
+static u32 max_wo_reseed = LRNG_DRNG_MAX_WITHOUT_RESEED;
+#ifdef CONFIG_LRNG_RUNTIME_MAX_WO_RESEED_CONFIG
+module_param(max_wo_reseed, uint, 0444);
+MODULE_PARM_DESC(max_wo_reseed,
+		 "Maximum number of DRNG generate operation without full reseed\n");
+#endif
+
 /********************************** Helper ************************************/
 
 bool lrng_get_available(void)
@@ -74,6 +81,7 @@ struct lrng_drng *lrng_drng_atomic_instance(void)
 void lrng_drng_reset(struct lrng_drng *drng)
 {
 	atomic_set(&drng->requests, LRNG_DRNG_RESEED_THRESH);
+	atomic_set(&drng->requests_since_fully_seeded, 0);
 	drng->last_seeded = jiffies;
 	drng->fully_seeded = false;
 	drng->force_reseed = true;
@@ -140,7 +148,7 @@ bool lrng_sp80090c_compliant(void)
 
 /* Inject a data buffer into the DRNG */
 static void lrng_drng_inject(struct lrng_drng *drng,
-			     const u8 *inbuf, u32 inbuflen)
+			     const u8 *inbuf, u32 inbuflen, bool fully_seeded)
 {
 	const char *drng_type = unlikely(drng == &lrng_drng_atomic) ?
 				"atomic" : "regular";
@@ -152,18 +160,31 @@ static void lrng_drng_inject(struct lrng_drng *drng,
 	if (drng->crypto_cb->lrng_drng_seed_helper(drng->drng,
 						   inbuf, inbuflen) < 0) {
 		pr_warn("seeding of %s DRNG failed\n", drng_type);
-		atomic_set(&drng->requests, 1);
+		drng->force_reseed = true;
 	} else {
+		int gc = LRNG_DRNG_RESEED_THRESH - atomic_read(&drng->requests);
+
 		pr_debug("%s DRNG stats since last seeding: %lu secs; generate calls: %d\n",
 			 drng_type,
 			 (time_after(jiffies, drng->last_seeded) ?
-			  (jiffies - drng->last_seeded) : 0) / HZ,
-			 (LRNG_DRNG_RESEED_THRESH -
-			  atomic_read(&drng->requests)));
+			  (jiffies - drng->last_seeded) : 0) / HZ, gc);
+
+		/* Count the numbers of generate ops since last fully seeded */
+		if (fully_seeded)
+			atomic_set(&drng->requests_since_fully_seeded, 0);
+		else
+			atomic_add(gc, &drng->requests_since_fully_seeded);
+
 		drng->last_seeded = jiffies;
 		atomic_set(&drng->requests, LRNG_DRNG_RESEED_THRESH);
 		drng->force_reseed = false;
 
+		if (!drng->fully_seeded) {
+			drng->fully_seeded = fully_seeded;
+			if (drng->fully_seeded)
+				pr_debug("DRNG fully seeded\n");
+		}
+
 		if (drng->drng == lrng_drng_atomic.drng) {
 			lrng_drng_atomic.last_seeded = jiffies;
 			atomic_set(&lrng_drng_atomic.requests,
@@ -181,15 +202,11 @@ static inline void _lrng_drng_seed(struct lrng_drng *drng)
 {
 	struct entropy_buf seedbuf __aligned(LRNG_KCAPI_ALIGN);
 
-	lrng_fill_seed_buffer(&seedbuf, lrng_get_seed_entropy_osr());
+	lrng_fill_seed_buffer(&seedbuf,
+			      lrng_get_seed_entropy_osr(drng->fully_seeded));
 	lrng_init_ops(&seedbuf);
-	lrng_drng_inject(drng, (u8 *)&seedbuf, sizeof(seedbuf));
-
-	if (!drng->fully_seeded) {
-		drng->fully_seeded = lrng_fully_seeded(&seedbuf);
-		if (drng->fully_seeded)
-			pr_debug("DRNG fully seeded\n");
-	}
+	lrng_drng_inject(drng, (u8 *)&seedbuf, sizeof(seedbuf),
+			 lrng_fully_seeded(drng->fully_seeded, &seedbuf));
 	memzero_explicit(&seedbuf, sizeof(seedbuf));
 }
 
@@ -220,7 +237,7 @@ static void lrng_drng_seed(struct lrng_drng *drng)
 			pr_warn("Error generating random numbers for atomic DRNG: %d\n",
 				ret);
 		} else {
-			lrng_drng_inject(&lrng_drng_atomic, seedbuf, ret);
+			lrng_drng_inject(&lrng_drng_atomic, seedbuf, ret, true);
 		}
 		memzero_explicit(&seedbuf, sizeof(seedbuf));
 	}
@@ -316,6 +333,11 @@ static int lrng_drng_get(struct lrng_drng *drng, u8 *outbuf, u32 outbuflen)
 
 	lrng_drngs_init_cc20(false);
 
+	/* If DRNG operated without proper reseed for too long, block LRNG */
+	BUILD_BUG_ON(LRNG_DRNG_MAX_WITHOUT_RESEED < LRNG_DRNG_RESEED_THRESH);
+	if (atomic_read_u32(&drng->requests_since_fully_seeded) > max_wo_reseed)
+		lrng_unset_fully_seeded(drng);
+
 	while (outbuflen) {
 		u32 todo = min_t(u32, outbuflen, LRNG_DRNG_MAX_REQSIZE);
 		int ret;
@@ -327,7 +349,7 @@ static int lrng_drng_get(struct lrng_drng *drng, u8 *outbuf, u32 outbuflen)
 			       lrng_drng_reseed_max_time * HZ)) {
 			if (likely(drng != &lrng_drng_atomic)) {
 				if (lrng_pool_trylock()) {
-					atomic_set(&drng->requests, 1);
+					drng->force_reseed = true;
 				} else {
 					lrng_drng_seed(drng);
 					lrng_pool_unlock();
diff --git a/drivers/char/lrng/lrng_archrandom.c b/drivers/char/lrng/lrng_es_archrandom.c
similarity index 100%
rename from drivers/char/lrng/lrng_archrandom.c
rename to drivers/char/lrng/lrng_es_archrandom.c
diff --git a/drivers/char/lrng/lrng_es_aux.c b/drivers/char/lrng/lrng_es_aux.c
new file mode 100644
index 000000000..9a12f7f79
--- /dev/null
+++ b/drivers/char/lrng/lrng_es_aux.c
@@ -0,0 +1,274 @@
+// SPDX-License-Identifier: GPL-2.0 OR BSD-2-Clause
+/*
+ * LRNG Slow Entropy Source: Auxiliary entropy pool
+ *
+ * Copyright (C) 2016 - 2021, Stephan Mueller <smueller@chronox.de>
+ */
+
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/lrng.h>
+
+#include "lrng_internal.h"
+
+/*
+ * This is the auxiliary pool
+ *
+ * The aux pool array is aligned to 8 bytes to comfort the kernel crypto API
+ * cipher implementations of the hash functions used to read the pool: for some
+ * accelerated implementations, we need an alignment to avoid a realignment
+ * which involves memcpy(). The alignment to 8 bytes should satisfy all crypto
+ * implementations.
+ */
+struct lrng_pool {
+	u8 aux_pool[LRNG_POOL_SIZE];	/* Aux pool: digest state */
+	atomic_t aux_entropy_bits;
+	atomic_t digestsize;		/* Digest size of used hash */
+	bool initialized;		/* Aux pool initialized? */
+
+	/* Serialize read of entropy pool and update of aux pool */
+	spinlock_t lock;
+};
+
+static struct lrng_pool lrng_pool __aligned(LRNG_KCAPI_ALIGN) = {
+	.aux_entropy_bits	= ATOMIC_INIT(0),
+	.digestsize		= ATOMIC_INIT(LRNG_ATOMIC_DIGEST_SIZE),
+	.initialized		= false,
+	.lock			= __SPIN_LOCK_UNLOCKED(lrng_pool.lock)
+};
+
+/********************************** Helper ***********************************/
+
+/* Entropy in bits present in aux pool */
+u32 lrng_avail_aux_entropy(void)
+{
+	/* Cap available entropy with max entropy */
+	u32 avail_bits = min_t(u32, lrng_get_digestsize(),
+			       atomic_read_u32(&lrng_pool.aux_entropy_bits));
+
+	/* Consider oversampling rate due to aux pool conditioning */
+	return lrng_reduce_by_osr(avail_bits);
+}
+
+/* Set the digest size of the used hash in bytes */
+static inline void lrng_set_digestsize(u32 digestsize)
+{
+	struct lrng_pool *pool = &lrng_pool;
+	u32 ent_bits = atomic_xchg_relaxed(&pool->aux_entropy_bits, 0),
+	    old_digestsize = lrng_get_digestsize();
+
+	atomic_set(&lrng_pool.digestsize, digestsize);
+
+	/*
+	 * In case the new digest is larger than the old one, cap the available
+	 * entropy to the old message digest used to process the existing data.
+	 */
+	ent_bits = min_t(u32, ent_bits, old_digestsize);
+	atomic_add(ent_bits, &pool->aux_entropy_bits);
+}
+
+/* Obtain the digest size provided by the used hash in bits */
+u32 lrng_get_digestsize(void)
+{
+	return atomic_read_u32(&lrng_pool.digestsize) << 3;
+}
+
+/* Set entropy content in user-space controllable aux pool */
+void lrng_pool_set_entropy(u32 entropy_bits)
+{
+	atomic_set(&lrng_pool.aux_entropy_bits, entropy_bits);
+}
+
+/*
+ * Replace old with new hash for auxiliary pool handling
+ *
+ * Assumption: the caller must guarantee that the new_cb is available during the
+ * entire operation (e.g. it must hold the write lock against pointer updating).
+ */
+int lrng_aux_switch_hash(const struct lrng_crypto_cb *new_cb, void *new_hash,
+			 const struct lrng_crypto_cb *old_cb)
+{
+	struct lrng_pool *pool = &lrng_pool;
+	struct shash_desc *shash = (struct shash_desc *)pool->aux_pool;
+	u8 digest[LRNG_MAX_DIGESTSIZE];
+	int ret;
+
+	if (!IS_ENABLED(CONFIG_LRNG_DRNG_SWITCH))
+		return -EOPNOTSUPP;
+
+	if (unlikely(!pool->initialized))
+		return 0;
+
+	/* Get the aux pool hash with old digest ... */
+	ret = old_cb->lrng_hash_final(shash, digest) ?:
+	      /* ... re-initialize the hash with the new digest ... */
+	      new_cb->lrng_hash_init(shash, new_hash) ?:
+	      /*
+	       * ... feed the old hash into the new state. We may feed
+	       * uninitialized memory into the new state, but this is
+	       * considered no issue and even good as we have some more
+	       * uncertainty here.
+	       */
+	      new_cb->lrng_hash_update(shash, digest, sizeof(digest));
+	if (!ret) {
+		lrng_set_digestsize(new_cb->lrng_hash_digestsize(new_hash));
+		pr_debug("Re-initialize aux entropy pool with hash %s\n",
+			 new_cb->lrng_hash_name());
+	}
+
+	memzero_explicit(digest, sizeof(digest));
+	return ret;
+}
+
+/* Insert data into auxiliary pool by using the hash update function. */
+static int
+lrng_pool_insert_aux_locked(const u8 *inbuf, u32 inbuflen, u32 entropy_bits)
+{
+	struct lrng_pool *pool = &lrng_pool;
+	struct shash_desc *shash = (struct shash_desc *)pool->aux_pool;
+	struct lrng_drng *drng = lrng_drng_init_instance();
+	const struct lrng_crypto_cb *crypto_cb;
+	unsigned long flags;
+	void *hash;
+	int ret;
+
+	entropy_bits = min_t(u32, entropy_bits, inbuflen << 3);
+
+	read_lock_irqsave(&drng->hash_lock, flags);
+
+	crypto_cb = drng->crypto_cb;
+	hash = drng->hash;
+
+	if (unlikely(!pool->initialized)) {
+		ret = crypto_cb->lrng_hash_init(shash, hash);
+		if (ret)
+			goto out;
+		pool->initialized = true;
+	}
+
+	ret = crypto_cb->lrng_hash_update(shash, inbuf, inbuflen);
+	if (ret)
+		goto out;
+
+	/*
+	 * Cap the available entropy to the hash output size compliant to
+	 * SP800-90B section 3.1.5.1 table 1.
+	 */
+	entropy_bits += atomic_read_u32(&pool->aux_entropy_bits);
+	atomic_set(&pool->aux_entropy_bits,
+		   min_t(u32, entropy_bits,
+			 crypto_cb->lrng_hash_digestsize(hash) << 3));
+
+out:
+	read_unlock_irqrestore(&drng->hash_lock, flags);
+	return ret;
+}
+
+int lrng_pool_insert_aux(const u8 *inbuf, u32 inbuflen, u32 entropy_bits)
+{
+	struct lrng_pool *pool = &lrng_pool;
+	unsigned long flags;
+	int ret;
+
+	spin_lock_irqsave(&pool->lock, flags);
+	ret = lrng_pool_insert_aux_locked(inbuf, inbuflen, entropy_bits);
+	spin_unlock_irqrestore(&pool->lock, flags);
+
+	lrng_pool_add_entropy();
+
+	return ret;
+}
+
+/************************* Get data from entropy pool *************************/
+
+/**
+ * Get auxiliary entropy pool and its entropy content for seed buffer.
+ * Caller must hold lrng_pool.pool->lock.
+ * @outbuf: buffer to store data in with size requested_bits
+ * @requested_bits: Requested amount of entropy
+ * @return: amount of entropy in outbuf in bits.
+ */
+static inline u32 lrng_get_aux_pool(u8 *outbuf, u32 requested_bits)
+{
+	struct lrng_pool *pool = &lrng_pool;
+	struct shash_desc *shash = (struct shash_desc *)pool->aux_pool;
+	struct lrng_drng *drng = lrng_drng_init_instance();
+	const struct lrng_crypto_cb *crypto_cb;
+	unsigned long flags;
+	void *hash;
+	u32 collected_ent_bits, returned_ent_bits, unused_bits = 0,
+	    digestsize;
+	u8 aux_output[LRNG_MAX_DIGESTSIZE];
+
+	if (unlikely(!pool->initialized))
+		return 0;
+
+	read_lock_irqsave(&drng->hash_lock, flags);
+
+	crypto_cb = drng->crypto_cb;
+	hash = drng->hash;
+	digestsize = crypto_cb->lrng_hash_digestsize(hash);
+
+	/* Ensure that no more than the size of aux_pool can be requested */
+	requested_bits = min_t(u32, requested_bits, (LRNG_MAX_DIGESTSIZE << 3));
+
+	/* Cap entropy with entropy counter from aux pool and the used digest */
+	collected_ent_bits = min_t(u32, digestsize << 3,
+			       atomic_xchg_relaxed(&pool->aux_entropy_bits, 0));
+
+	/* We collected too much entropy and put the overflow back */
+	if (collected_ent_bits > (requested_bits + lrng_compress_osr())) {
+		/* Amount of bits we collected too much */
+		unused_bits = collected_ent_bits - requested_bits;
+		/* Put entropy back */
+		atomic_add(unused_bits, &pool->aux_entropy_bits);
+		/* Fix collected entropy */
+		collected_ent_bits = requested_bits;
+	}
+
+	/* Apply oversampling: discount requested oversampling rate */
+	returned_ent_bits = lrng_reduce_by_osr(collected_ent_bits);
+
+	pr_debug("obtained %u bits by collecting %u bits of entropy from aux pool, %u bits of entropy remaining\n",
+		 returned_ent_bits, collected_ent_bits, unused_bits);
+
+	/* Get the digest for the aux pool to be returned to the caller ... */
+	if (crypto_cb->lrng_hash_final(shash, aux_output) ||
+	    /*
+	     * ... and re-initialize the aux state. Do not add the aux pool
+	     * digest for backward secrecy as it will be added with the
+	     * insertion of the complete seed buffer after it has been filled.
+	     */
+	    crypto_cb->lrng_hash_init(shash, hash)) {
+		returned_ent_bits = 0;
+	} else {
+		/*
+		 * Do not truncate the output size exactly to collected_ent_bits
+		 * as the aux pool may contain data that is not credited with
+		 * entropy, but we want to use them to stir the DRNG state.
+		 */
+		memcpy(outbuf, aux_output, requested_bits >> 3);
+	}
+
+	read_unlock_irqrestore(&drng->hash_lock, flags);
+	memzero_explicit(aux_output, digestsize);
+	return returned_ent_bits;
+}
+
+void lrng_get_backtrack_aux(struct entropy_buf *entropy_buf, u32 requested_bits)
+{
+	struct lrng_pool *pool = &lrng_pool;
+	unsigned long flags;
+
+	/* Ensure aux pool extraction and backtracking op are atomic */
+	spin_lock_irqsave(&pool->lock, flags);
+
+	entropy_buf->a_bits = lrng_get_aux_pool(entropy_buf->a, requested_bits);
+
+	/* Mix the extracted data back into pool for backtracking resistance */
+	if (lrng_pool_insert_aux_locked((u8 *)entropy_buf,
+					sizeof(struct entropy_buf), 0))
+		pr_warn("Backtracking resistance operation failed\n");
+
+	spin_unlock_irqrestore(&pool->lock, flags);
+}
diff --git a/drivers/char/lrng/lrng_sw_noise.c b/drivers/char/lrng/lrng_es_irq.c
similarity index 89%
rename from drivers/char/lrng/lrng_sw_noise.c
rename to drivers/char/lrng/lrng_es_irq.c
index b1994ecce..675425d87 100644
--- a/drivers/char/lrng/lrng_sw_noise.c
+++ b/drivers/char/lrng/lrng_es_irq.c
@@ -10,11 +10,12 @@
 #include <asm/irq_regs.h>
 #include <asm/ptrace.h>
 #include <crypto/hash.h>
+#include <linux/gcd.h>
 #include <linux/lrng.h>
 #include <linux/random.h>
 
 #include "lrng_internal.h"
-#include "lrng_sw_noise.h"
+#include "lrng_es_irq.h"
 
 /* Number of interrupts required for LRNG_DRNG_SECURITY_STRENGTH_BITS entropy */
 static u32 lrng_irq_entropy_bits = LRNG_IRQ_ENTROPY_BITS;
@@ -83,6 +84,94 @@ static DEFINE_PER_CPU(u8 [LRNG_POOL_SIZE], lrng_pcpu_pool)
 static DEFINE_PER_CPU(spinlock_t, lrng_pcpu_lock);
 static DEFINE_PER_CPU(bool, lrng_pcpu_lock_init) = false;
 
+/* Number of time stamps analyzed to calculate a GCD */
+#define LRNG_GCD_WINDOW_SIZE	100
+static u32 lrng_gcd_history[LRNG_GCD_WINDOW_SIZE];
+static atomic_t lrng_gcd_history_ptr = ATOMIC_INIT(-1);
+
+/* The common divisor for all timestamps */
+static u32 lrng_gcd_timer = 0;
+
+static inline bool lrng_gcd_tested(void)
+{
+	return (lrng_gcd_timer != 0);
+}
+
+/* Set the GCD for use in IRQ ES - if 0, the GCD calculation is restarted. */
+static inline void _lrng_gcd_set(u32 running_gcd)
+{
+	lrng_gcd_timer = running_gcd;
+	mb();
+}
+
+static void lrng_gcd_set(u32 running_gcd)
+{
+	if (!lrng_gcd_tested()) {
+		_lrng_gcd_set(running_gcd);
+		pr_debug("Setting GCD to %u\n", running_gcd);
+	}
+}
+
+u32 lrng_gcd_analyze(u32 *history, size_t nelem)
+{
+	u32 running_gcd = 0;
+	size_t i;
+
+	/* Now perform the analysis on the accumulated time data. */
+	for (i = 0; i < nelem; i++) {
+		/*
+		 * NOTE: this would be the place to add more analysis on the
+		 * appropriateness of the timer like checking the presence
+		 * of sufficient variations in the timer.
+		 */
+
+		/*
+		 * This calculates the gcd of all the time values. that is
+		 * gcd(time_1, time_2, ..., time_nelem)
+		 *
+		 * Some timers increment by a fixed (non-1) amount each step.
+		 * This code checks for such increments, and allows the library
+		 * to output the number of such changes have occurred.
+		 */
+		running_gcd = (u32)gcd(history[i], running_gcd);
+
+		/* Zeroize data */
+		history[i] = 0;
+	}
+
+	return running_gcd;
+}
+
+static void jent_gcd_add_value(u32 time)
+{
+	u32 ptr = (u32)atomic_inc_return_relaxed(&lrng_gcd_history_ptr);
+
+	if (ptr < LRNG_GCD_WINDOW_SIZE) {
+		lrng_gcd_history[ptr] = time;
+	} else if (ptr == LRNG_GCD_WINDOW_SIZE) {
+		u32 gcd = lrng_gcd_analyze(lrng_gcd_history,
+					   LRNG_GCD_WINDOW_SIZE);
+
+		if (!gcd)
+			gcd = 1;
+
+		/*
+		 * Ensure that we have variations in the time stamp below the
+		 * given value. This is just a safety measure to prevent the GCD
+		 * becoming too large.
+		 */
+		if (gcd >= 1000) {
+			pr_warn("calculated GCD is larger than expected: %u\n",
+				gcd);
+			gcd = 1000;
+		}
+
+		/*  Adjust all deltas by the observed (small) common factor. */
+		lrng_gcd_set(gcd);
+		atomic_set(&lrng_gcd_history_ptr, 0);
+	}
+}
+
 /* Return boolean whether LRNG identified presence of high-resolution timer */
 bool lrng_pool_highres_timer(void)
 {
@@ -162,6 +251,9 @@ void lrng_pcpu_reset(void)
 {
 	int cpu;
 
+	/* Trigger GCD calculation anew. */
+	_lrng_gcd_set(0);
+
 	for_each_online_cpu(cpu)
 		atomic_set(per_cpu_ptr(&lrng_pcpu_array_irqs, cpu), 0);
 }
@@ -372,8 +464,8 @@ u32 lrng_pcpu_pool_hash(u8 *outbuf, u32 requested_bits, bool fully_seeded)
 	if (ret)
 		goto err;
 
-	requested_irqs = lrng_entropy_to_data(requested_bits) +
-			 lrng_compress_osr();
+	requested_irqs = lrng_entropy_to_data(requested_bits +
+					      lrng_compress_osr());
 
 	/*
 	 * Harvest entropy from each per-CPU hash state - even though we may
@@ -647,12 +739,14 @@ static inline void lrng_time_process(void)
 {
 	u32 now_time = random_get_entropy();
 
-	if (unlikely(!lrng_state_fully_seeded())) {
-		/* During boot time, we process the full time stamp */
+	if (unlikely(!lrng_gcd_tested())) {
+		/* When GCD is unknown, we process the full time stamp */
 		lrng_time_process_common(now_time, _lrng_pcpu_array_add_u32);
+		jent_gcd_add_value(now_time);
 	} else {
-		/* Runtime operation */
-		lrng_time_process_common(now_time & LRNG_DATA_SLOTSIZE_MASK,
+		/* GCD is known and applied */
+		lrng_time_process_common((now_time / lrng_gcd_timer) &
+					 LRNG_DATA_SLOTSIZE_MASK,
 					 lrng_pcpu_array_add_slot);
 	}
 
diff --git a/drivers/char/lrng/lrng_sw_noise.h b/drivers/char/lrng/lrng_es_irq.h
similarity index 100%
rename from drivers/char/lrng/lrng_sw_noise.h
rename to drivers/char/lrng/lrng_es_irq.h
diff --git a/drivers/char/lrng/lrng_jent.c b/drivers/char/lrng/lrng_es_jent.c
similarity index 96%
rename from drivers/char/lrng/lrng_jent.c
rename to drivers/char/lrng/lrng_es_jent.c
index 2599ab935..e98152b4c 100644
--- a/drivers/char/lrng/lrng_jent.c
+++ b/drivers/char/lrng/lrng_es_jent.c
@@ -31,8 +31,8 @@ static struct rand_data *lrng_jent_state;
 static int __init lrng_jent_initialize(void)
 {
 	/* Initialize the Jitter RNG after the clocksources are initialized. */
-	lrng_jent_state = jent_lrng_entropy_collector();
-	if (!lrng_jent_state) {
+	if (jent_entropy_init() ||
+	    (lrng_jent_state = jent_entropy_collector_alloc(1, 0)) == NULL) {
 		jitterrng = 0;
 		pr_info("Jitter RNG unusable on current system\n");
 		return 0;
diff --git a/drivers/char/lrng/lrng_pool.c b/drivers/char/lrng/lrng_es_mgr.c
similarity index 52%
rename from drivers/char/lrng/lrng_pool.c
rename to drivers/char/lrng/lrng_es_mgr.c
index ee9c494e1..d0d66ff36 100644
--- a/drivers/char/lrng/lrng_pool.c
+++ b/drivers/char/lrng/lrng_es_mgr.c
@@ -1,7 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0 OR BSD-2-Clause
 /*
  * LRNG Entropy sources management
- * LRNG Slow Entropy Source: Auxiliary entropy pool
  *
  * Copyright (C) 2016 - 2021, Stephan Mueller <smueller@chronox.de>
  */
@@ -16,7 +15,7 @@
 #include <linux/workqueue.h>
 
 #include "lrng_internal.h"
-#include "lrng_sw_noise.h"
+#include "lrng_es_irq.h"
 
 struct lrng_state {
 	bool can_invalidate;		/* Can invalidate batched entropy? */
@@ -42,32 +41,6 @@ struct lrng_state {
 	struct work_struct lrng_seed_work;	/* (re)seed work queue */
 };
 
-/*
- * This is the auxiliary pool
- *
- * The aux pool array is aligned to 8 bytes to comfort the kernel crypto API
- * cipher implementations of the hash functions used to read the pool: for some
- * accelerated implementations, we need an alignment to avoid a realignment
- * which involves memcpy(). The alignment to 8 bytes should satisfy all crypto
- * implementations.
- */
-struct lrng_pool {
-	u8 aux_pool[LRNG_POOL_SIZE];	/* Aux pool: digest state */
-	atomic_t aux_entropy_bits;
-	atomic_t digestsize;		/* Digest size of used hash */
-	bool initialized;		/* Aux pool initialized? */
-
-	/* Serialize read of entropy pool and update of aux pool */
-	spinlock_t lock;
-};
-
-static struct lrng_pool lrng_pool __aligned(LRNG_KCAPI_ALIGN) = {
-	.aux_entropy_bits	= ATOMIC_INIT(0),
-	.digestsize		= ATOMIC_INIT(LRNG_ATOMIC_DIGEST_SIZE),
-	.initialized		= false,
-	.lock			= __SPIN_LOCK_UNLOCKED(lrng_pool.lock)
-};
-
 static struct lrng_state lrng_state = {
 	false, false, false, false, false, false, true, true,
 	.boot_entropy_thresh	= ATOMIC_INIT(LRNG_INIT_ENTROPY_BITS),
@@ -99,40 +72,6 @@ static inline void lrng_state_exseed_allow_all(void)
 	lrng_state_exseed_set(lrng_noise_source_user, true);
 }
 
-/* Entropy in bits present in aux pool */
-u32 lrng_avail_aux_entropy(void)
-{
-	/* Cap available entropy with max entropy */
-	u32 avail_bits = min_t(u32, lrng_get_digestsize(),
-			       atomic_read_u32(&lrng_pool.aux_entropy_bits));
-
-	/* Consider oversampling rate due to aux pool conditioning */
-	return lrng_reduce_by_osr(avail_bits);
-}
-
-/* Set the digest size of the used hash in bytes */
-static inline void lrng_set_digestsize(u32 digestsize)
-{
-	struct lrng_pool *pool = &lrng_pool;
-	u32 ent_bits = atomic_xchg_relaxed(&pool->aux_entropy_bits, 0),
-	    old_digestsize = lrng_get_digestsize();
-
-	atomic_set(&lrng_pool.digestsize, digestsize);
-
-	/*
-	 * In case the new digest is larger than the old one, cap the available
-	 * entropy to the old message digest used to process the existing data.
-	 */
-	ent_bits = min_t(u32, ent_bits, old_digestsize);
-	atomic_add(ent_bits, &pool->aux_entropy_bits);
-}
-
-/* Obtain the digest size provided by the used hash in bits */
-u32 lrng_get_digestsize(void)
-{
-	return atomic_read_u32(&lrng_pool.digestsize) << 3;
-}
-
 /*
  * Reading of the LRNG pool is only allowed by one caller. The reading is
  * only performed to (re)seed DRNGs. Thus, if this "lock" is already taken,
@@ -161,7 +100,7 @@ void lrng_set_entropy_thresh(u32 new_entropy_bits)
  */
 void lrng_reset_state(void)
 {
-	atomic_set(&lrng_pool.aux_entropy_bits, 0);
+	lrng_pool_set_entropy(0);
 	lrng_pcpu_reset();
 	lrng_state.lrng_operational = false;
 	lrng_state.lrng_fully_seeded = false;
@@ -195,26 +134,44 @@ bool lrng_state_operational(void)
 }
 
 /* Policy to check whether entropy buffer contains full seeded entropy */
-bool lrng_fully_seeded(struct entropy_buf *eb)
+bool lrng_fully_seeded(bool fully_seeded, struct entropy_buf *eb)
 {
 	return ((eb->a_bits + eb->b_bits + eb->c_bits + eb->d_bits) >=
-		lrng_get_seed_entropy_osr());
+		lrng_get_seed_entropy_osr(fully_seeded));
 }
 
-/* Disable the fully seeded and operational mode */
-void lrng_unset_operational(void)
+/* Mark one DRNG as not fully seeded */
+void lrng_unset_fully_seeded(struct lrng_drng *drng)
 {
+	drng->fully_seeded = false;
 	lrng_pool_all_numa_nodes_seeded(false);
-	lrng_state.lrng_operational = false;
-	lrng_state.lrng_fully_seeded = false;
+
+	/*
+	 * The init DRNG instance must always be fully seeded as this instance
+	 * is the fall-back if any of the per-NUMA node DRNG instances is
+	 * insufficiently seeded. Thus, we mark the entire LRNG as
+	 * non-operational if the initial DRNG becomes not fully seeded.
+	 */
+	if (drng == lrng_drng_init_instance() && lrng_state_operational()) {
+		pr_debug("LRNG set to non-operational\n");
+		lrng_state.lrng_operational = false;
+		lrng_state.lrng_fully_seeded = false;
+
+		/* If sufficient entropy is available, reseed now. */
+		lrng_pool_add_entropy();
+	}
 }
 
 /* Policy to enable LRNG operational mode */
 static inline void lrng_set_operational(u32 external_es)
 {
+	/* LRNG is operational if the initial DRNG is fully seeded ... */
 	if (lrng_state.lrng_fully_seeded &&
+	    /* ... and either internal ES SP800-90B startup is complete ... */
 	    (lrng_sp80090b_startup_complete() ||
-	     (lrng_get_seed_entropy_osr() <= external_es))) {
+	    /* ... or the external ES provided sufficient entropy. */
+	     (lrng_get_seed_entropy_osr(lrng_state_fully_seeded()) <=
+	      external_es))) {
 		lrng_state.lrng_operational = true;
 		lrng_process_ready_list();
 		lrng_init_wakeup();
@@ -222,12 +179,6 @@ static inline void lrng_set_operational(u32 external_es)
 	}
 }
 
-/* Set entropy content in user-space controllable aux pool */
-void lrng_pool_set_entropy(u32 entropy_bits)
-{
-	atomic_set(&lrng_pool.aux_entropy_bits, entropy_bits);
-}
-
 /* Available entropy in the entire LRNG considering all entropy sources */
 u32 lrng_avail_entropy(void)
 {
@@ -264,7 +215,8 @@ void lrng_init_ops(struct entropy_buf *eb)
 	if (state->lrng_operational)
 		return;
 
-	requested_bits = lrng_get_seed_entropy_osr();
+	requested_bits = lrng_get_seed_entropy_osr(
+					state->all_online_numa_node_seeded);
 
 	/*
 	 * Entropy provided by external entropy sources - if they provide
@@ -277,7 +229,7 @@ void lrng_init_ops(struct entropy_buf *eb)
 	if (state->lrng_fully_seeded) {
 		lrng_set_operational(external_es);
 		lrng_set_entropy_thresh(requested_bits);
-	} else if (lrng_fully_seeded(eb)) {
+	} else if (lrng_fully_seeded(state->all_online_numa_node_seeded, eb)) {
 		if (state->can_invalidate)
 			invalidate_batched_entropy();
 
@@ -345,110 +297,6 @@ int __init rand_initialize(void)
 	return 0;
 }
 
-/*
- * Replace old with new hash for auxiliary pool handling
- *
- * Assumption: the caller must guarantee that the new_cb is available during the
- * entire operation (e.g. it must hold the write lock against pointer updating).
- */
-int lrng_aux_switch_hash(const struct lrng_crypto_cb *new_cb, void *new_hash,
-			 const struct lrng_crypto_cb *old_cb)
-{
-	struct lrng_pool *pool = &lrng_pool;
-	struct shash_desc *shash = (struct shash_desc *)pool->aux_pool;
-	u8 digest[LRNG_MAX_DIGESTSIZE];
-	int ret;
-
-	if (!IS_ENABLED(CONFIG_LRNG_DRNG_SWITCH))
-		return -EOPNOTSUPP;
-
-	if (unlikely(!pool->initialized))
-		return 0;
-
-	/* Get the aux pool hash with old digest ... */
-	ret = old_cb->lrng_hash_final(shash, digest) ?:
-	      /* ... re-initialize the hash with the new digest ... */
-	      new_cb->lrng_hash_init(shash, new_hash) ?:
-	      /*
-	       * ... feed the old hash into the new state. We may feed
-	       * uninitialized memory into the new state, but this is
-	       * considered no issue and even good as we have some more
-	       * uncertainty here.
-	       */
-	      new_cb->lrng_hash_update(shash, digest, sizeof(digest));
-	if (!ret) {
-		lrng_set_digestsize(new_cb->lrng_hash_digestsize(new_hash));
-		pr_debug("Re-initialize aux entropy pool with hash %s\n",
-			 new_cb->lrng_hash_name());
-	}
-
-	memzero_explicit(digest, sizeof(digest));
-	return ret;
-}
-
-/*
- * Insert data into auxiliary pool by hashing the input data together with
- * the auxiliary pool. The message digest is the new state of the auxiliary
- * pool.
- */
-static int
-lrng_pool_insert_aux_locked(const u8 *inbuf, u32 inbuflen, u32 entropy_bits)
-{
-	struct lrng_pool *pool = &lrng_pool;
-	struct shash_desc *shash = (struct shash_desc *)pool->aux_pool;
-	struct lrng_drng *drng = lrng_drng_init_instance();
-	const struct lrng_crypto_cb *crypto_cb;
-	unsigned long flags;
-	void *hash;
-	int ret;
-
-	entropy_bits = min_t(u32, entropy_bits, inbuflen << 3);
-
-	read_lock_irqsave(&drng->hash_lock, flags);
-
-	crypto_cb = drng->crypto_cb;
-	hash = drng->hash;
-
-	if (unlikely(!pool->initialized)) {
-		ret = crypto_cb->lrng_hash_init(shash, hash);
-		if (ret)
-			goto out;
-		pool->initialized = true;
-	}
-
-	ret = crypto_cb->lrng_hash_update(shash, inbuf, inbuflen);
-	if (ret)
-		goto out;
-
-	/*
-	 * Cap the available entropy to the hash output size compliant to
-	 * SP800-90B section 3.1.5.1 table 1.
-	 */
-	entropy_bits += atomic_read_u32(&pool->aux_entropy_bits);
-	atomic_set(&pool->aux_entropy_bits,
-		   min_t(u32, entropy_bits,
-			 crypto_cb->lrng_hash_digestsize(hash) << 3));
-
-out:
-	read_unlock_irqrestore(&drng->hash_lock, flags);
-	return ret;
-}
-
-int lrng_pool_insert_aux(const u8 *inbuf, u32 inbuflen, u32 entropy_bits)
-{
-	struct lrng_pool *pool = &lrng_pool;
-	unsigned long flags;
-	int ret;
-
-	spin_lock_irqsave(&pool->lock, flags);
-	ret = lrng_pool_insert_aux_locked(inbuf, inbuflen, entropy_bits);
-	spin_unlock_irqrestore(&pool->lock, flags);
-
-	lrng_pool_add_entropy();
-
-	return ret;
-}
-
 /* Hot code path during boot - mix data into entropy pool during boot */
 void lrng_pool_add_entropy(void)
 {
@@ -479,89 +327,11 @@ void lrng_pool_add_entropy(void)
 		lrng_drng_seed_work(NULL);
 }
 
-/************************* Get data from entropy pool *************************/
-
-/**
- * Get auxiliary entropy pool and its entropy content for seed buffer.
- * Caller must hold lrng_pool.pool->lock.
- * @outbuf: buffer to store data in with size requested_bits
- * @requested_bits: Requested amount of entropy
- * @return: amount of entropy in outbuf in bits.
- */
-static inline u32 lrng_get_aux_pool(u8 *outbuf, u32 requested_bits)
-{
-	struct lrng_pool *pool = &lrng_pool;
-	struct shash_desc *shash = (struct shash_desc *)pool->aux_pool;
-	struct lrng_drng *drng = lrng_drng_init_instance();
-	const struct lrng_crypto_cb *crypto_cb;
-	unsigned long flags;
-	void *hash;
-	u32 collected_ent_bits, returned_ent_bits, unused_bits = 0,
-	    digestsize;
-	u8 aux_output[LRNG_MAX_DIGESTSIZE];
-
-	if (unlikely(!pool->initialized))
-		return 0;
-
-	read_lock_irqsave(&drng->hash_lock, flags);
-
-	crypto_cb = drng->crypto_cb;
-	hash = drng->hash;
-	digestsize = crypto_cb->lrng_hash_digestsize(hash);
-
-	/* Ensure that no more than the size of aux_pool can be requested */
-	requested_bits = min_t(u32, requested_bits, (LRNG_MAX_DIGESTSIZE << 3));
-
-	/* Cap entropy with entropy counter from aux pool and the used digest */
-	collected_ent_bits = min_t(u32, digestsize << 3,
-			       atomic_xchg_relaxed(&pool->aux_entropy_bits, 0));
-
-	/* We collected too much entropy and put the overflow back */
-	if (collected_ent_bits > (requested_bits + lrng_compress_osr())) {
-		/* Amount of bits we collected too much */
-		unused_bits = collected_ent_bits - requested_bits;
-		/* Put entropy back */
-		atomic_add(unused_bits, &pool->aux_entropy_bits);
-		/* Fix collected entropy */
-		collected_ent_bits = requested_bits;
-	}
-
-	/* Apply oversampling: discount requested oversampling rate */
-	returned_ent_bits = lrng_reduce_by_osr(collected_ent_bits);
-
-	pr_debug("obtained %u bits by collecting %u bits of entropy from aux pool, %u bits of entropy remaining\n",
-		 returned_ent_bits, collected_ent_bits, unused_bits);
-
-	/* Get the digest for the aux pool to be returned to the caller ... */
-	if (crypto_cb->lrng_hash_final(shash, aux_output) ||
-	    /*
-	     * ... and re-initialize the aux state. Do not add the aux pool
-	     * digest for backward secrecy as it will be added with the
-	     * insertion of the complete seed buffer after it has been filled.
-	     */
-	    crypto_cb->lrng_hash_init(shash, hash)) {
-		returned_ent_bits = 0;
-	} else {
-		/*
-		 * Do not truncate the output size exactly to collected_ent_bits
-		 * as the aux pool may contain data that is not credited with
-		 * entropy, but we want to use them to stir the DRNG state.
-		 */
-		memcpy(outbuf, aux_output, requested_bits >> 3);
-	}
-
-	read_unlock_irqrestore(&drng->hash_lock, flags);
-	memzero_explicit(aux_output, digestsize);
-	return returned_ent_bits;
-}
-
 /* Fill the seed buffer with data from the noise sources */
 void lrng_fill_seed_buffer(struct entropy_buf *entropy_buf, u32 requested_bits)
 {
-	struct lrng_pool *pool = &lrng_pool;
 	struct lrng_state *state = &lrng_state;
-	unsigned long flags;
-	u32 pcpu_request, req_ent = lrng_sp80090c_compliant() ?
+	u32 req_ent = lrng_sp80090c_compliant() ?
 			  lrng_security_strength() : LRNG_MIN_SEED_ENTROPY_BITS;
 
 	/* Guarantee that requested bits is a multiple of bytes */
@@ -581,30 +351,13 @@ void lrng_fill_seed_buffer(struct entropy_buf *entropy_buf, u32 requested_bits)
 		goto wakeup;
 	}
 
-	/* Ensure aux pool extraction and backtracking op are atomic */
-	spin_lock_irqsave(&pool->lock, flags);
-
 	/* Concatenate the output of the entropy sources. */
-	entropy_buf->a_bits = lrng_get_aux_pool(entropy_buf->a, requested_bits);
-
-	/*
-	 * If the aux pool returned entropy, pull respective less from per-CPU
-	 * pool, but attempt to at least get LRNG_MIN_SEED_ENTROPY_BITS entropy.
-	 */
-	pcpu_request = max_t(u32, requested_bits - entropy_buf->a_bits,
-			     LRNG_MIN_SEED_ENTROPY_BITS);
-	entropy_buf->b_bits = lrng_pcpu_pool_hash(entropy_buf->b, pcpu_request,
+	entropy_buf->b_bits = lrng_pcpu_pool_hash(entropy_buf->b,
+						  requested_bits,
 						  state->lrng_fully_seeded);
-
 	entropy_buf->c_bits = lrng_get_arch(entropy_buf->c, requested_bits);
 	entropy_buf->d_bits = lrng_get_jent(entropy_buf->d, requested_bits);
-
-	/* Mix the extracted data back into pool for backtracking resistance */
-	if (lrng_pool_insert_aux_locked((u8 *)entropy_buf,
-					sizeof(struct entropy_buf), 0))
-		pr_warn("Backtracking resistance operation failed\n");
-
-	spin_unlock_irqrestore(&pool->lock, flags);
+	lrng_get_backtrack_aux(entropy_buf, requested_bits);
 
 	/* allow external entropy provider to provide seed */
 	lrng_state_exseed_allow_all();
diff --git a/drivers/char/lrng/lrng_internal.h b/drivers/char/lrng/lrng_internal.h
index a4ed142d1..a21e5be71 100644
--- a/drivers/char/lrng/lrng_internal.h
+++ b/drivers/char/lrng/lrng_internal.h
@@ -39,6 +39,20 @@
  */
 #define LRNG_DRNG_RESEED_THRESH		(1<<20)
 
+/*
+ * Maximum DRNG generation operations without reseed having full entropy
+ * This value defines the absolute maximum value of DRNG generation operations
+ * without a reseed holding full entropy. LRNG_DRNG_RESEED_THRESH is the
+ * threshold when a new reseed is attempted. But it is possible that this fails
+ * to deliver full entropy. In this case the DRNG will continue to provide data
+ * even though it was not reseeded with full entropy. To avoid in the extreme
+ * case that no reseed is performed for too long, this threshold is enforced.
+ * If that absolute low value is reached, the LRNG is marked as not operational.
+ *
+ * This value is allowed to be changed.
+ */
+#define LRNG_DRNG_MAX_WITHOUT_RESEED	(1<<30)
+
 /*
  * Number of interrupts to be recorded to assume that DRNG security strength
  * bits of entropy are received.
@@ -168,6 +182,7 @@ int lrng_pcpu_switch_hash(int node,
 			  const struct lrng_crypto_cb *old_cb);
 u32 lrng_pcpu_pool_hash(u8 *outbuf, u32 requested_bits, bool fully_seeded);
 void lrng_pcpu_array_add_u32(u32 data);
+u32 lrng_gcd_analyze(u32 *history, size_t nelem);
 
 /****************************** DRNG processing *******************************/
 
@@ -177,6 +192,8 @@ struct lrng_drng {
 	void *hash;				/* Hash handle */
 	const struct lrng_crypto_cb *crypto_cb;	/* Crypto callbacks */
 	atomic_t requests;			/* Number of DRNG requests */
+	atomic_t requests_since_fully_seeded;	/* Number DRNG requests since
+						   last fully seeded */
 	unsigned long last_seeded;		/* Last time it was seeded */
 	bool fully_seeded;			/* Is DRNG fully seeded? */
 	bool force_reseed;			/* Force a reseed */
@@ -273,33 +290,6 @@ enum lrng_external_noise_source {
 	lrng_noise_source_user
 };
 
-u32 lrng_avail_aux_entropy(void);
-u32 lrng_get_digestsize(void);
-
-/* Obtain the security strength of the LRNG in bits */
-static inline u32 lrng_security_strength(void)
-{
-	/*
-	 * We use a hash to read the entropy in the entropy pool. According to
-	 * SP800-90B table 1, the entropy can be at most the digest size.
-	 * Considering this together with the last sentence in section 3.1.5.1.2
-	 * the security strength of a (approved) hash is equal to its output
-	 * size. On the other hand the entropy cannot be larger than the
-	 * security strength of the used DRBG.
-	 */
-	return min_t(u32, LRNG_FULL_SEED_ENTROPY_BITS, lrng_get_digestsize());
-}
-
-static inline u32 lrng_get_seed_entropy_osr(void)
-{
-	u32 requested_bits = lrng_security_strength();
-
-	/* Apply oversampling during initialization according to SP800-90C */
-	if (lrng_sp80090c_compliant())
-		requested_bits += CONFIG_LRNG_SEED_BUFFER_INIT_ADD_BITS;
-	return requested_bits;
-}
-
 void lrng_set_entropy_thresh(u32 new);
 u32 lrng_avail_entropy(void);
 void lrng_reset_state(void);
@@ -314,10 +304,6 @@ int lrng_pool_trylock(void);
 void lrng_pool_unlock(void);
 void lrng_pool_all_numa_nodes_seeded(bool set);
 bool lrng_pool_highres_timer(void);
-void lrng_pool_set_entropy(u32 entropy_bits);
-int lrng_aux_switch_hash(const struct lrng_crypto_cb *new_cb, void *new_hash,
-			 const struct lrng_crypto_cb *old_cb);
-int lrng_pool_insert_aux(const u8 *inbuf, u32 inbuflen, u32 entropy_bits);
 void lrng_pool_add_entropy(void);
 
 struct entropy_buf {
@@ -332,11 +318,46 @@ struct entropy_buf {
 	u32 now, a_bits, b_bits, c_bits, d_bits;
 };
 
-bool lrng_fully_seeded(struct entropy_buf *eb);
-void lrng_unset_operational(void);
+bool lrng_fully_seeded(bool fully_seeded, struct entropy_buf *eb);
+void lrng_unset_fully_seeded(struct lrng_drng *drng);
 void lrng_fill_seed_buffer(struct entropy_buf *entropy_buf, u32 requested_bits);
 void lrng_init_ops(struct entropy_buf *eb);
 
+/*********************** Auxiliary Pool Entropy Source ************************/
+
+u32 lrng_avail_aux_entropy(void);
+u32 lrng_get_digestsize(void);
+void lrng_pool_set_entropy(u32 entropy_bits);
+int lrng_aux_switch_hash(const struct lrng_crypto_cb *new_cb, void *new_hash,
+			 const struct lrng_crypto_cb *old_cb);
+int lrng_pool_insert_aux(const u8 *inbuf, u32 inbuflen, u32 entropy_bits);
+void lrng_get_backtrack_aux(struct entropy_buf *entropy_buf,
+			    u32 requested_bits);
+
+/* Obtain the security strength of the LRNG in bits */
+static inline u32 lrng_security_strength(void)
+{
+	/*
+	 * We use a hash to read the entropy in the entropy pool. According to
+	 * SP800-90B table 1, the entropy can be at most the digest size.
+	 * Considering this together with the last sentence in section 3.1.5.1.2
+	 * the security strength of a (approved) hash is equal to its output
+	 * size. On the other hand the entropy cannot be larger than the
+	 * security strength of the used DRBG.
+	 */
+	return min_t(u32, LRNG_FULL_SEED_ENTROPY_BITS, lrng_get_digestsize());
+}
+
+static inline u32 lrng_get_seed_entropy_osr(bool fully_seeded)
+{
+	u32 requested_bits = lrng_security_strength();
+
+	/* Apply oversampling during initialization according to SP800-90C */
+	if (lrng_sp80090c_compliant() && !fully_seeded)
+		requested_bits += CONFIG_LRNG_SEED_BUFFER_INIT_ADD_BITS;
+	return requested_bits;
+}
+
 /************************** Health Test linking code **************************/
 
 enum lrng_health_res {
diff --git a/drivers/char/lrng/lrng_proc.c b/drivers/char/lrng/lrng_proc.c
index 30bc0a1a6..a842c6c89 100644
--- a/drivers/char/lrng/lrng_proc.c
+++ b/drivers/char/lrng/lrng_proc.c
@@ -12,7 +12,7 @@
 #include <linux/uuid.h>
 
 #include "lrng_internal.h"
-#include "lrng_sw_noise.h"
+#include "lrng_es_irq.h"
 
 /*
  * This function is used to return both the bootid UUID, and random
diff --git a/drivers/char/lrng/lrng_selftest.c b/drivers/char/lrng/lrng_selftest.c
index cd2b64184..e219f7ea8 100644
--- a/drivers/char/lrng/lrng_selftest.c
+++ b/drivers/char/lrng/lrng_selftest.c
@@ -30,12 +30,13 @@
 
 #include "lrng_chacha20.h"
 #include "lrng_internal.h"
-#include "lrng_sw_noise.h"
+#include "lrng_es_irq.h"
 
 #define LRNG_SELFTEST_PASSED		0
 #define LRNG_SEFLTEST_ERROR_TIME	(1 << 0)
 #define LRNG_SEFLTEST_ERROR_CHACHA20	(1 << 1)
 #define LRNG_SEFLTEST_ERROR_HASH	(1 << 2)
+#define LRNG_SEFLTEST_ERROR_GCD		(1 << 3)
 #define LRNG_SELFTEST_NOT_EXECUTED	0xffffffff
 
 static u32 lrng_data_selftest_ptr = 0;
@@ -306,12 +307,29 @@ static unsigned int lrng_chacha20_drng_selftest(void)
 	return LRNG_SEFLTEST_ERROR_CHACHA20;
 }
 
+static unsigned int lrng_gcd_selftest(void)
+{
+	u32 history[10];
+	unsigned int i;
+
+#define LRNG_GCD_SELFTEST 3
+	for (i = 0; i < ARRAY_SIZE(history); i++)
+		history[i] = i * LRNG_GCD_SELFTEST;
+
+	if (lrng_gcd_analyze(history, ARRAY_SIZE(history)) == LRNG_GCD_SELFTEST)
+		return LRNG_SELFTEST_PASSED;
+
+	pr_err("LRNG GCD self-test FAILED\n");
+	return LRNG_SEFLTEST_ERROR_GCD;
+}
+
 static int lrng_selftest(void)
 {
 	unsigned int ret = lrng_data_process_selftest();
 
 	ret |= lrng_chacha20_drng_selftest();
 	ret |= lrng_hash_selftest();
+	ret |= lrng_gcd_selftest();
 
 	if (ret) {
 		if (IS_ENABLED(CONFIG_LRNG_SELFTEST_PANIC))
diff --git a/drivers/char/lrng/lrng_switch.c b/drivers/char/lrng/lrng_switch.c
index 233906740..f3b2f30d1 100644
--- a/drivers/char/lrng/lrng_switch.c
+++ b/drivers/char/lrng/lrng_switch.c
@@ -118,22 +118,17 @@ static int lrng_drng_switch(struct lrng_drng *drng_store,
 		pr_info("Entropy pool read-hash allocated for DRNG for NUMA node %d\n",
 			node);
 
-		if (lrng_state_min_seeded())
-			lrng_set_entropy_thresh(lrng_get_seed_entropy_osr());
-
 		/* Reseed if previous LRNG security strength was insufficient */
 		if (current_security_strength < lrng_security_strength())
 			drng_store->force_reseed = true;
 
 		/* Force oversampling seeding as we initialize DRNG */
-		if (IS_ENABLED(CONFIG_LRNG_OVERSAMPLE_ENTROPY_SOURCES)) {
-			drng_store->force_reseed = true;
-			drng_store->fully_seeded = false;
+		if (IS_ENABLED(CONFIG_LRNG_OVERSAMPLE_ENTROPY_SOURCES))
+			lrng_unset_fully_seeded(drng_store);
 
-			/* Block output interfaces until again fully seeded */
-			if (drng_store == lrng_drng_init_instance())
-				lrng_unset_operational();
-		}
+		if (lrng_state_min_seeded())
+			lrng_set_entropy_thresh(lrng_get_seed_entropy_osr(
+						drng_store->fully_seeded));
 
 		/* ChaCha20 serves as atomic instance left untouched. */
 		if (old_drng != &chacha20) {
diff --git a/include/crypto/internal/jitterentropy.h b/include/crypto/internal/jitterentropy.h
index 6e07d86ea..c83fff32d 100644
--- a/include/crypto/internal/jitterentropy.h
+++ b/include/crypto/internal/jitterentropy.h
@@ -15,6 +15,3 @@ extern int jent_read_entropy(struct rand_data *ec, unsigned char *data,
 extern struct rand_data *jent_entropy_collector_alloc(unsigned int osr,
 						      unsigned int flags);
 extern void jent_entropy_collector_free(struct rand_data *entropy_collector);
-
-/* Access to statically allocated Jitter RNG instance */
-extern struct rand_data *jent_lrng_entropy_collector(void);
-- 
2.33.0.328.g8b7c11b866

