From 4a8e2d1094939cd0b45a749e01b1823ce8e0559f Mon Sep 17 00:00:00 2001
From: Piotr Gorski <lucjan.lucjanov@gmail.com>
Date: Tue, 31 Aug 2021 12:54:47 +0200
Subject: [PATCH] LL: Implement ll-branding v5.14

Signed-off-by: Piotr Gorski <lucjan.lucjanov@gmail.com>
---
 drivers/cpufreq/cpufreq_ondemand.c | 9 +++++++++
 fs/dcache.c                        | 4 ++++
 include/linux/pagemap.h            | 4 ++++
 init/Kconfig                       | 4 ++++
 kernel/sched/alt_core.c            | 8 ++++++++
 kernel/sched/core.c                | 8 ++++++++
 mm/huge_memory.c                   | 4 ++++
 mm/page-writeback.c                | 8 ++++++++
 mm/vmscan.c                        | 8 ++++++++
 9 files changed, 57 insertions(+)

diff --git a/drivers/cpufreq/cpufreq_ondemand.c b/drivers/cpufreq/cpufreq_ondemand.c
index ac361a8b1..063364e8c 100644
--- a/drivers/cpufreq/cpufreq_ondemand.c
+++ b/drivers/cpufreq/cpufreq_ondemand.c
@@ -18,10 +18,19 @@
 #include "cpufreq_ondemand.h"
 
 /* On-demand governor macros */
+#if defined(CONFIG_LL_BRANDING) && defined(CONFIG_SCHED_ALT)
+#define DEF_FREQUENCY_UP_THRESHOLD		(55)
+#define DEF_SAMPLING_DOWN_FACTOR		(5)
+#else
 #define DEF_FREQUENCY_UP_THRESHOLD		(80)
 #define DEF_SAMPLING_DOWN_FACTOR		(1)
+#endif
 #define MAX_SAMPLING_DOWN_FACTOR		(100000)
+#if defined(CONFIG_LL_BRANDING) && defined(CONFIG_SCHED_ALT)
+#define MICRO_FREQUENCY_UP_THRESHOLD		(63)
+#else
 #define MICRO_FREQUENCY_UP_THRESHOLD		(95)
+#endif
 #define MICRO_FREQUENCY_MIN_SAMPLE_RATE		(10000)
 #define MIN_FREQUENCY_UP_THRESHOLD		(1)
 #define MAX_FREQUENCY_UP_THRESHOLD		(100)
diff --git a/fs/dcache.c b/fs/dcache.c
index 34a37dbd6..fa43037b9 100644
--- a/fs/dcache.c
+++ b/fs/dcache.c
@@ -71,7 +71,11 @@
  * If no ancestor relationship:
  * arbitrary, since it's serialized on rename_lock
  */
+#ifdef CONFIG_LL_BRANDING
+int sysctl_vfs_cache_pressure __read_mostly = 50;
+#else
 int sysctl_vfs_cache_pressure __read_mostly = 100;
+#endif
 EXPORT_SYMBOL_GPL(sysctl_vfs_cache_pressure);
 
 __cacheline_aligned_in_smp DEFINE_SEQLOCK(rename_lock);
diff --git a/include/linux/pagemap.h b/include/linux/pagemap.h
index ed02aa522..f3a6ae245 100644
--- a/include/linux/pagemap.h
+++ b/include/linux/pagemap.h
@@ -852,7 +852,11 @@ struct readahead_control {
 		._index = i,						\
 	}
 
+#ifdef CONFIG_LL_BRANDING
+#define VM_READAHEAD_PAGES	(SZ_8M / PAGE_SIZE)
+#else
 #define VM_READAHEAD_PAGES	(SZ_128K / PAGE_SIZE)
+#endif
 
 void page_cache_ra_unbounded(struct readahead_control *,
 		unsigned long nr_to_read, unsigned long lookahead_count);
diff --git a/init/Kconfig b/init/Kconfig
index c207ab699..b30b9056c 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -107,6 +107,10 @@ config THREAD_INFO_IN_TASK
 
 menu "General setup"
 
+config LL_BRANDING
+	bool "Add Linux Lucjan branding"
+	default y
+
 config BROKEN
 	bool
 
diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index fe4b95a7c..246102583 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -77,7 +77,11 @@ __read_mostly int sysctl_resched_latency_warn_once = 1;
 #define STOP_PRIO		(MAX_RT_PRIO - 1)
 
 /* Default time slice is 4 in ms, can be set via kernel parameter "sched_timeslice" */
+#ifdef CONFIG_LL_BRANDING
+u64 sched_timeslice_ns __read_mostly = (2 << 20);
+#else
 u64 sched_timeslice_ns __read_mostly = (4 << 20);
+#endif
 
 static inline void requeue_task(struct task_struct *p, struct rq *rq);
 
@@ -111,7 +115,11 @@ early_param("sched_timeslice", sched_timeslice);
  * 1: Deboost and requeue task. (default)
  * 2: Set rq skip task.
  */
+#ifdef CONFIG_LL_BRANDING
+int sched_yield_type __read_mostly = 2;
+#else
 int sched_yield_type __read_mostly = 1;
+#endif
 
 #ifdef CONFIG_SMP
 static cpumask_t sched_rq_pending_mask ____cacheline_aligned_in_smp;
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index a4badc27e..675e5245e 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -74,7 +74,11 @@ __read_mostly int sysctl_resched_latency_warn_once = 1;
  * Number of tasks to iterate in a single balance run.
  * Limited because this is done with IRQs disabled.
  */
+#ifdef CONFIG_LL_BRANDING
+const_debug unsigned int sysctl_sched_nr_migrate = 256;
+#else
 const_debug unsigned int sysctl_sched_nr_migrate = 32;
+#endif
 
 /*
  * period over which we measure -rt task CPU usage in us.
@@ -368,7 +372,11 @@ static inline void sched_core_dequeue(struct rq *rq, struct task_struct *p) { }
  * part of the period that we allow rt tasks to run in us.
  * default: 0.95s
  */
+#ifdef CONFIG_LL_BRANDING
+int sysctl_sched_rt_runtime = 980000;
+#else
 int sysctl_sched_rt_runtime = 950000;
+#endif
 
 
 /*
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index d5ccbfb50..d282fc428 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -54,7 +54,11 @@ unsigned long transparent_hugepage_flags __read_mostly =
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE_MADVISE
 	(1<<TRANSPARENT_HUGEPAGE_REQ_MADV_FLAG)|
 #endif
+#ifdef CONFIG_LL_BRANDING
+	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_KSWAPD_OR_MADV_FLAG)|
+#else
 	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_REQ_MADV_FLAG)|
+#endif
 	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_KHUGEPAGED_FLAG)|
 	(1<<TRANSPARENT_HUGEPAGE_USE_ZERO_PAGE_FLAG);
 
diff --git a/mm/page-writeback.c b/mm/page-writeback.c
index 505802c79..3afe4eaf7 100644
--- a/mm/page-writeback.c
+++ b/mm/page-writeback.c
@@ -70,7 +70,11 @@ static long ratelimit_pages = 32;
 /*
  * Start background writeback (via writeback threads) at this percentage
  */
+#ifdef CONFIG_LL_BRANDING
+int dirty_background_ratio = 20;
+#else
 int dirty_background_ratio = 10;
+#endif
 
 /*
  * dirty_background_bytes starts at 0 (disabled) so that it is a function of
@@ -87,7 +91,11 @@ int vm_highmem_is_dirtyable;
 /*
  * The generator of dirty data starts writeback at this percentage
  */
+#ifdef CONFIG_LL_BRANDING
+int vm_dirty_ratio = 50;
+#else
 int vm_dirty_ratio = 20;
+#endif
 
 /*
  * vm_dirty_bytes starts at 0 (disabled) so that it is a function of
diff --git a/mm/vmscan.c b/mm/vmscan.c
index a3e72a242..26d4a112e 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -201,7 +201,11 @@ extern unsigned long sysctl_unevictable_anon_kbytes_min;
 /*
  * From 0 .. 200.  Higher means more swappy.
  */
+#ifdef CONFIG_LL_BRANDING
+int vm_swappiness = 30;
+#else
 int vm_swappiness = 60;
+#endif
 
 static void set_task_reclaim_state(struct task_struct *task,
 				   struct reclaim_state *rs)
@@ -4085,7 +4089,11 @@ static bool age_lruvec(struct lruvec *lruvec, struct scan_control *sc,
 }
 
 /* Protect the working set accessed within the last N milliseconds. */
+#ifdef CONFIG_LL_BRANDING
+static unsigned long lru_gen_min_ttl __read_mostly = 1000;
+#else
 static unsigned long lru_gen_min_ttl __read_mostly;
+#endif
 
 static void lru_gen_age_node(struct pglist_data *pgdat, struct scan_control *sc)
 {
-- 
2.33.0.610.gcefe983a32

