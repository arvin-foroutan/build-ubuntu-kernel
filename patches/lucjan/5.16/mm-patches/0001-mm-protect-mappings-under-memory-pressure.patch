From 4022ad00997367febe045c16e08a413204a55a38 Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@natalenko.name>
Date: Sun, 5 Dec 2021 12:01:23 +0100
Subject: [PATCH] mm: protect mappings under memory pressure

Signed-off-by: Oleksandr Natalenko <oleksandr@natalenko.name>
---
 .../admin-guide/kernel-parameters.txt         |  16 ++
 Documentation/admin-guide/sysctl/vm.rst       |  46 ++++++
 kernel/sysctl.c                               | 122 ++++++++++++++
 mm/Kconfig                                    |  63 ++++++++
 mm/vmscan.c                                   | 150 ++++++++++++++++++
 5 files changed, 397 insertions(+)

diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt
index 2fba82431..b8d46e749 100644
--- a/Documentation/admin-guide/kernel-parameters.txt
+++ b/Documentation/admin-guide/kernel-parameters.txt
@@ -6199,6 +6199,22 @@
 			  P	Enable page structure init time poisoning
 			  -	Disable all of the above options
 
+	vm_unevictable_file_kbytes_low=nn[KMG]	[KNL]
+		Keep some file pages still mapped under memory pressure,
+		value defines a threshold to activate file pages eviction throttling.
+
+	vm_unevictable_file_kbytes_min=nn[KMG]	[KNL]
+		Keep some file pages still mapped under memory pressure,
+		value defines a hard limit.
+
+	vm_unevictable_anon_kbytes_low=nn[KMG]	[KNL]
+		Keep some anonymous pages under memory pressure,
+		value defines a threshold to throttle swapping of anonymous pages.
+
+	vm_unevictable_anon_kbytes_min=nn[KMG]	[KNL]
+		Keep some anonymous pages under memory pressure,
+		value defines a hard limit.
+
 	vmalloc=nn[KMG]	[KNL,BOOT] Forces the vmalloc area to have an exact
 			size of <nn>. This can be used to increase the
 			minimum size (128MB on x86). It can also be used to
diff --git a/Documentation/admin-guide/sysctl/vm.rst b/Documentation/admin-guide/sysctl/vm.rst
index 5e7952021..5c69841a8 100644
--- a/Documentation/admin-guide/sysctl/vm.rst
+++ b/Documentation/admin-guide/sysctl/vm.rst
@@ -68,6 +68,10 @@ Currently, these files are in /proc/sys/vm:
 - stat_refresh
 - numa_stat
 - swappiness
+- unevictable_file_kbytes_low
+- unevictable_file_kbytes_min
+- unevictable_anon_kbytes_low
+- unevictable_anon_kbytes_min
 - unprivileged_userfaultfd
 - user_reserve_kbytes
 - vfs_cache_pressure
@@ -881,6 +885,48 @@ calls without any restrictions.
 The default value is 0.
 
 
+unevictable_file_kbytes_low
+===========================
+
+Keep some file pages still mapped under memory pressure to avoid potential
+disk thrashing that may occur due to evicting running executables code.
+This implements soft eviction throttling, and some file pages can still
+be discarded.
+
+Setting it to 0 effectively disables this feature.
+
+
+unevictable_file_kbytes_min
+===========================
+
+Keep all file pages still mapped under memory pressure to avoid potential
+disk thrashing that may occur due to evicting running executables code.
+This is the hard limit.
+
+Setting it to 0 effectively disables this feature.
+
+
+unevictable_anon_kbytes_low
+===========================
+
+Keep some anonymous pages still mapped under memory pressure to avoid
+potential stalls that may occur due to swapping.
+This implements soft swapping throttling, and some anonymous pages can
+still be swapped out.
+
+Setting it to 0 effectively disables this feature.
+
+
+unevictable_anon_kbytes_min
+===========================
+
+Keep all anonymous pages still mapped under memory pressure to avoid
+potential stalls that may occur due to swapping.
+This is the hard limit.
+
+Setting it to 0 effectively disables this feature.
+
+
 user_reserve_kbytes
 ===================
 
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index 083be6af2..e732eb21f 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -2721,6 +2721,92 @@ static struct ctl_table kern_table[] = {
 	{ }
 };
 
+#if defined(CONFIG_UNEVICTABLE_FILE)
+extern unsigned long vm_unevictable_file_kbytes_low;
+extern unsigned long vm_unevictable_file_kbytes_min;
+
+static int vm_unevictable_file_kbytes_low_handler(struct ctl_table *table, int write,
+						  void *buffer, size_t *length, loff_t *ppos)
+{
+	int rc;
+
+	rc = proc_doulongvec_minmax(table, write, buffer, length, ppos);
+	if (rc)
+		return rc;
+
+	if (write) {
+		if (vm_unevictable_file_kbytes_low <
+		    vm_unevictable_file_kbytes_min)
+		    vm_unevictable_file_kbytes_min =
+		    vm_unevictable_file_kbytes_low;
+	}
+
+	return 0;
+}
+
+static int vm_unevictable_file_kbytes_min_handler(struct ctl_table *table, int write,
+						  void *buffer, size_t *length, loff_t *ppos)
+{
+	int rc;
+
+	rc = proc_doulongvec_minmax(table, write, buffer, length, ppos);
+	if (rc)
+		return rc;
+
+	if (write) {
+		if (vm_unevictable_file_kbytes_min >
+		    vm_unevictable_file_kbytes_low)
+		    vm_unevictable_file_kbytes_low =
+		    vm_unevictable_file_kbytes_min;
+	}
+
+	return 0;
+}
+#endif /* CONFIG_UNEVICTABLE_FILE */
+
+#if defined(CONFIG_UNEVICTABLE_ANON)
+extern unsigned long vm_unevictable_anon_kbytes_low;
+extern unsigned long vm_unevictable_anon_kbytes_min;
+
+static int vm_unevictable_anon_kbytes_low_handler(struct ctl_table *table, int write,
+						  void *buffer, size_t *length, loff_t *ppos)
+{
+	int rc;
+
+	rc = proc_doulongvec_minmax(table, write, buffer, length, ppos);
+	if (rc)
+		return rc;
+
+	if (write) {
+		if (vm_unevictable_anon_kbytes_low <
+		    vm_unevictable_anon_kbytes_min)
+		    vm_unevictable_anon_kbytes_min =
+		    vm_unevictable_anon_kbytes_low;
+	}
+
+	return 0;
+}
+
+static int vm_unevictable_anon_kbytes_min_handler(struct ctl_table *table, int write,
+						  void *buffer, size_t *length, loff_t *ppos)
+{
+	int rc;
+
+	rc = proc_doulongvec_minmax(table, write, buffer, length, ppos);
+	if (rc)
+		return rc;
+
+	if (write) {
+		if (vm_unevictable_anon_kbytes_min >
+		    vm_unevictable_anon_kbytes_low)
+		    vm_unevictable_anon_kbytes_low =
+		    vm_unevictable_anon_kbytes_min;
+	}
+
+	return 0;
+}
+#endif /* CONFIG_UNEVICTABLE_ANON */
+
 static struct ctl_table vm_table[] = {
 	{
 		.procname	= "overcommit_memory",
@@ -3178,6 +3264,42 @@ static struct ctl_table vm_table[] = {
 		.extra2		= SYSCTL_ONE,
 	},
 #endif
+#if defined(CONFIG_UNEVICTABLE_FILE)
+	{
+		.procname	= "unevictable_file_kbytes_low",
+		.data		= &vm_unevictable_file_kbytes_low,
+		.maxlen		= sizeof(vm_unevictable_file_kbytes_low),
+		.mode		= 0644,
+		.proc_handler	= vm_unevictable_file_kbytes_low_handler,
+		.extra1		= &zero_ul,
+	},
+	{
+		.procname	= "unevictable_file_kbytes_min",
+		.data		= &vm_unevictable_file_kbytes_min,
+		.maxlen		= sizeof(vm_unevictable_file_kbytes_min),
+		.mode		= 0644,
+		.proc_handler	= vm_unevictable_file_kbytes_min_handler,
+		.extra1		= &zero_ul,
+	},
+#endif /* CONFIG_UNEVICTABLE_FILE */
+#if defined(CONFIG_UNEVICTABLE_ANON)
+	{
+		.procname	= "unevictable_anon_kbytes_low",
+		.data		= &vm_unevictable_anon_kbytes_low,
+		.maxlen		= sizeof(vm_unevictable_anon_kbytes_low),
+		.mode		= 0644,
+		.proc_handler	= vm_unevictable_anon_kbytes_low_handler,
+		.extra1		= &zero_ul,
+	},
+	{
+		.procname	= "unevictable_anon_kbytes_min",
+		.data		= &vm_unevictable_anon_kbytes_min,
+		.maxlen		= sizeof(vm_unevictable_anon_kbytes_min),
+		.mode		= 0644,
+		.proc_handler	= vm_unevictable_anon_kbytes_min_handler,
+		.extra1		= &zero_ul,
+	},
+#endif /* CONFIG_UNEVICTABLE_ANON */
 	{ }
 };
 
diff --git a/mm/Kconfig b/mm/Kconfig
index 356f4f2c7..b390a445a 100644
--- a/mm/Kconfig
+++ b/mm/Kconfig
@@ -47,6 +47,69 @@ config SPARSEMEM_MANUAL
 
 endchoice
 
+config UNEVICTABLE_FILE
+	bool "Keep some file pages under memory pressure"
+	def_bool n
+	help
+	  Keep some file pages still mapped under memory pressure
+	  to avoid potential disk thrashing that may occur due to
+	  evicting running executables code.
+
+	  The UNEVICTABLE_FILE_KBYTES_LOW value defines a threshold
+	  to activate file pages eviction throttling.
+	  The vm.unevictable_file_kbytes_low sysctl knob is used to
+	  change the amount in the runtime (setting it to 0
+	  effectively disables this feature).
+
+	  The UNEVICTABLE_FILE_KBYTES_MIN value sets the amount of
+	  pages to keep as a hard limit.
+	  The vm.unevictable_file_kbytes_min sysctl knob is used to
+	  change the amount in the runtime (setting it to 0
+	  effectively disables this feature).
+
+	  See also: Documentation/admin-guide/sysctl/vm.rst
+
+config UNEVICTABLE_FILE_KBYTES_LOW
+	int "Default value for vm.unevictable_file_kbytes_low"
+	depends on UNEVICTABLE_FILE
+	default "0"
+
+config UNEVICTABLE_FILE_KBYTES_MIN
+	int "Default value for vm.unevictable_file_kbytes_min"
+	depends on UNEVICTABLE_FILE
+	default "0"
+
+config UNEVICTABLE_ANON
+	bool "Keep some anonymous pages under memory pressure"
+	def_bool n
+	help
+	  Keep some anonymous pages still mapped under memory pressure
+	  to avoid potential stalls that may occur due to swapping.
+
+	  The UNEVICTABLE_ANON_KBYTES_LOW value defines a threshold
+	  to throttle swapping of anonymous pages.
+	  The vm.unevictable_anon_kbytes_low sysctl knob is used to
+	  change the amount in the runtime (setting it to 0
+	  effectively disables this feature).
+
+	  The UNEVICTABLE_ANON_KBYTES_MIN value sets the amount of
+	  pages to keep as a hard limit.
+	  The vm.unevictable_anon_kbytes_min sysctl knob is used to
+	  change the amount in the runtime (setting it to 0
+	  effectively disables this feature).
+
+	  See also: Documentation/admin-guide/sysctl/vm.rst
+
+config UNEVICTABLE_ANON_KBYTES_LOW
+	int "Default value for vm.unevictable_anon_kbytes_low"
+	depends on UNEVICTABLE_ANON
+	default "0"
+
+config UNEVICTABLE_ANON_KBYTES_MIN
+	int "Default value for vm.unevictable_anon_kbytes_min"
+	depends on UNEVICTABLE_ANON
+	default "0"
+
 config SPARSEMEM
 	def_bool y
 	depends on (!SELECT_MEMORY_MODEL && ARCH_SPARSEMEM_ENABLE) || SPARSEMEM_MANUAL
diff --git a/mm/vmscan.c b/mm/vmscan.c
index 700434db5..a99861203 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -119,9 +119,25 @@ struct scan_control {
 	/* There is easily reclaimable cold cache in the current node */
 	unsigned int cache_trim_mode:1;
 
+#if defined(CONFIG_UNEVICTABLE_FILE)
+	/* The file pages on the current node are low */
+	unsigned int file_is_low:1;
+
+	/* The file pages on the current node are minimal */
+	unsigned int file_is_min:1;
+#endif
+
 	/* The file pages on the current node are dangerously low */
 	unsigned int file_is_tiny:1;
 
+#if defined(CONFIG_UNEVICTABLE_ANON)
+	/* The anonymous pages on the current node are low */
+	unsigned int anon_is_low:1;
+
+	/* The anonymous pages on the current node are minimal */
+	unsigned int anon_is_min:1;
+#endif
+
 	/* Always discard instead of demoting to lower tier memory */
 	unsigned int no_demotion:1;
 
@@ -171,6 +187,78 @@ struct scan_control {
 #define prefetchw_prev_lru_page(_page, _base, _field) do { } while (0)
 #endif
 
+#if defined(CONFIG_UNEVICTABLE_FILE)
+#if CONFIG_UNEVICTABLE_FILE_KBYTES_LOW < 0
+#error "CONFIG_UNEVICTABLE_FILE_KBYTES_LOW must be >= 0"
+#endif
+#if CONFIG_UNEVICTABLE_FILE_KBYTES_MIN < 0
+#error "CONFIG_UNEVICTABLE_FILE_KBYTES_MIN must be >= 0"
+#endif
+#if CONFIG_UNEVICTABLE_FILE_KBYTES_LOW < CONFIG_UNEVICTABLE_FILE_KBYTES_MIN
+#error "CONFIG_UNEVICTABLE_FILE_KBYTES_LOW must be >= CONFIG_UNEVICTABLE_FILE_KBYTES_MIN"
+#endif
+unsigned long vm_unevictable_file_kbytes_low __read_mostly =
+	CONFIG_UNEVICTABLE_FILE_KBYTES_LOW;
+unsigned long vm_unevictable_file_kbytes_min __read_mostly =
+	CONFIG_UNEVICTABLE_FILE_KBYTES_MIN;
+
+static int __init vm_unevictable_file_kbytes_low_setup(char *str)
+{
+	vm_unevictable_file_kbytes_low = memparse(str, NULL) >> 10;
+	if (vm_unevictable_file_kbytes_low < vm_unevictable_file_kbytes_min)
+	    vm_unevictable_file_kbytes_min = vm_unevictable_file_kbytes_low;
+
+	return 1;
+}
+__setup("vm_unevictable_file_kbytes_low=", vm_unevictable_file_kbytes_low_setup);
+
+static int __init vm_unevictable_file_kbytes_min_setup(char *str)
+{
+	vm_unevictable_file_kbytes_min = memparse(str, NULL) >> 10;
+	if (vm_unevictable_file_kbytes_min > vm_unevictable_file_kbytes_low)
+	    vm_unevictable_file_kbytes_low = vm_unevictable_file_kbytes_min;
+
+	return 1;
+}
+__setup("vm_unevictable_file_kbytes_min=", vm_unevictable_file_kbytes_min_setup);
+#endif /* CONFIG_UNEVICTABLE_FILE */
+
+#if defined(CONFIG_UNEVICTABLE_ANON)
+#if CONFIG_UNEVICTABLE_ANON_KBYTES_LOW < 0
+#error "CONFIG_UNEVICTABLE_ANON_KBYTES_LOW must be >= 0"
+#endif
+#if CONFIG_UNEVICTABLE_ANON_KBYTES_MIN < 0
+#error "CONFIG_UNEVICTABLE_ANON_KBYTES_MIN must be >= 0"
+#endif
+#if CONFIG_UNEVICTABLE_ANON_KBYTES_LOW < CONFIG_UNEVICTABLE_ANON_KBYTES_MIN
+#error "CONFIG_UNEVICTABLE_ANON_KBYTES_LOW must be >= CONFIG_UNEVICTABLE_ANON_KBYTES_MIN"
+#endif
+unsigned long vm_unevictable_anon_kbytes_low __read_mostly =
+	CONFIG_UNEVICTABLE_ANON_KBYTES_LOW;
+unsigned long vm_unevictable_anon_kbytes_min __read_mostly =
+	CONFIG_UNEVICTABLE_ANON_KBYTES_MIN;
+
+static int __init vm_unevictable_anon_kbytes_low_setup(char *str)
+{
+	vm_unevictable_anon_kbytes_low = memparse(str, NULL) >> 10;
+	if (vm_unevictable_anon_kbytes_low < vm_unevictable_anon_kbytes_min)
+	    vm_unevictable_anon_kbytes_min = vm_unevictable_anon_kbytes_low;
+
+	return 1;
+}
+__setup("vm_unevictable_anon_kbytes_low=", vm_unevictable_anon_kbytes_low_setup);
+
+static int __init vm_unevictable_anon_kbytes_min_setup(char *str)
+{
+	vm_unevictable_anon_kbytes_min = memparse(str, NULL) >> 10;
+	if (vm_unevictable_anon_kbytes_min > vm_unevictable_anon_kbytes_low)
+	    vm_unevictable_anon_kbytes_low = vm_unevictable_anon_kbytes_min;
+
+	return 1;
+}
+__setup("vm_unevictable_anon_kbytes_min=", vm_unevictable_anon_kbytes_min_setup);
+#endif /* CONFIG_UNEVICTABLE_ANON */
+
 /*
  * From 0 .. 200.  Higher means more swappy.
  */
@@ -2918,6 +3006,23 @@ static void get_scan_count(struct lruvec *lruvec, struct scan_control *sc,
 			BUG();
 		}
 
+#if defined(CONFIG_UNEVICTABLE_FILE)
+		if (file && scan) {
+			if (sc->file_is_low)
+				scan = min(scan, SWAP_CLUSTER_MAX >> sc->priority);
+			else if (sc->file_is_min)
+				scan = 0;
+		}
+#endif
+#if defined(CONFIG_UNEVICTABLE_ANON)
+		if (!file && scan) {
+			if (sc->anon_is_low)
+				scan = min(scan, SWAP_CLUSTER_MAX >> sc->priority);
+			else if (sc->anon_is_min)
+				scan = 0;
+		}
+#endif
+
 		nr[lru] = scan;
 	}
 }
@@ -3180,6 +3285,10 @@ static void shrink_node_memcgs(pg_data_t *pgdat, struct scan_control *sc)
 	} while ((memcg = mem_cgroup_iter(target_memcg, memcg, NULL)));
 }
 
+#if defined(CONFIG_UNEVICTABLE_FILE) || defined(CONFIG_UNEVICTABLE_ANON)
+#define K(x) ((x) << (PAGE_SHIFT - 10))
+#endif
+
 static void shrink_node(pg_data_t *pgdat, struct scan_control *sc)
 {
 	struct reclaim_state *reclaim_state = current->reclaim_state;
@@ -3263,11 +3372,26 @@ static void shrink_node(pg_data_t *pgdat, struct scan_control *sc)
 	if (!cgroup_reclaim(sc)) {
 		unsigned long total_high_wmark = 0;
 		unsigned long free, anon;
+#if defined(CONFIG_UNEVICTABLE_FILE)
+		unsigned long reclaimable_file, clean_file, dirty_file;
+#endif
+#if defined(CONFIG_UNEVICTABLE_ANON)
+		unsigned long reclaimable_anon;
+#endif
 		int z;
 
 		free = sum_zone_node_page_state(pgdat->node_id, NR_FREE_PAGES);
 		file = node_page_state(pgdat, NR_ACTIVE_FILE) +
 			   node_page_state(pgdat, NR_INACTIVE_FILE);
+#if defined(CONFIG_UNEVICTABLE_FILE)
+		reclaimable_file = file + node_page_state(pgdat, NR_ISOLATED_FILE);
+		dirty_file = node_page_state(pgdat, NR_FILE_DIRTY);
+#endif
+#if defined(CONFIG_UNEVICTABLE_ANON)
+		reclaimable_anon = node_page_state(pgdat, NR_ACTIVE_ANON) +
+				   node_page_state(pgdat, NR_INACTIVE_ANON) +
+				   node_page_state(pgdat, NR_ISOLATED_ANON);
+#endif
 
 		for (z = 0; z < MAX_NR_ZONES; z++) {
 			struct zone *zone = &pgdat->node_zones[z];
@@ -3288,6 +3412,32 @@ static void shrink_node(pg_data_t *pgdat, struct scan_control *sc)
 			file + free <= total_high_wmark &&
 			!(sc->may_deactivate & DEACTIVATE_ANON) &&
 			anon >> sc->priority;
+
+#if defined(CONFIG_UNEVICTABLE_FILE)
+		/*
+		 * node_page_state() sum can go out of sync since
+		 * all the values are not read at once
+		 */
+		if (unlikely(reclaimable_file < dirty_file))
+			/*
+			 * in this case assume the system does not have
+			 * clean file pages anymore
+			 */
+			clean_file = 0;
+		else
+			clean_file = reclaimable_file - dirty_file;
+
+		sc->file_is_low = K(clean_file) < vm_unevictable_file_kbytes_low &&
+			          K(clean_file) > vm_unevictable_file_kbytes_min;
+
+		sc->file_is_min = K(clean_file) <= vm_unevictable_file_kbytes_min;
+#endif
+#if defined(CONFIG_UNEVICTABLE_ANON)
+		sc->anon_is_low = K(reclaimable_anon) < vm_unevictable_anon_kbytes_low &&
+				  K(reclaimable_anon) > vm_unevictable_anon_kbytes_min;
+
+		sc->anon_is_min = K(reclaimable_anon) <= vm_unevictable_anon_kbytes_min;
+#endif
 	}
 
 	shrink_node_memcgs(pgdat, sc);
-- 
2.34.1.75.gabe6bb3905

