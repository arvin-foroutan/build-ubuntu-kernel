From 71a01f566ac83270d2b6741aa04a0f617c176c34 Mon Sep 17 00:00:00 2001
From: Jan Kara <jack@suse.cz>
Date: Wed, 30 Mar 2022 14:42:48 +0200
Subject: [PATCH 07/13] bfq: Drop pointless unlock-lock pair

In bfq_insert_request() we unlock bfqd->lock only to call
trace_block_rq_insert() and then lock bfqd->lock again. This is really
pointless since tracing is disabled if we really care about performance
and even if the tracepoint is enabled, it is a quick call.

Signed-off-by: Jan Kara <jack@suse.cz>
---
 block/bfq-iosched.c | 3 ---
 1 file changed, 3 deletions(-)

diff --git a/block/bfq-iosched.c b/block/bfq-iosched.c
index ece7f965e..ad51f8e75 100644
--- a/block/bfq-iosched.c
+++ b/block/bfq-iosched.c
@@ -6999,11 +6999,8 @@ static void bfq_insert_request(struct blk_mq_hw_ctx *hctx, struct request *rq,
 		return;
 	}
 
-	spin_unlock_irq(&bfqd->lock);
-
 	trace_block_rq_insert(rq);
 
-	spin_lock_irq(&bfqd->lock);
 	// XXX next function also takes a lock on bfqq
 	bfqq = bfq_init_rq(rq);
 
-- 
2.36.0.44.g0f828332d5

