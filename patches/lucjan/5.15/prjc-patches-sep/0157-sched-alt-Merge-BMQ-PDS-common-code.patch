From 3edcdba079e0ed7e825d1ba4868f1700b3d8c217 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Tue, 18 May 2021 10:40:43 +0000
Subject: [PATCH 157/232] sched/alt: Merge BMQ&PDS common code.

---
 kernel/sched/alt_core.c | 43 ++++++++++++-------
 kernel/sched/bmq.h      | 17 +-------
 kernel/sched/pds.h      | 91 ++++++++++++++++++-----------------------
 3 files changed, 70 insertions(+), 81 deletions(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 407d5d441298..c81a9fc6a140 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -149,9 +149,34 @@ static cpumask_t sched_rq_watermark[SCHED_BITS] ____cacheline_aligned_in_smp;
 #include "pds.h"
 #endif
 
+/* sched_queue related functions */
+static inline void sched_queue_init(struct sched_queue *q)
+{
+	int i;
+
+	bitmap_zero(q->bitmap, SCHED_BITS);
+	for(i = 0; i < SCHED_BITS; i++)
+		INIT_LIST_HEAD(&q->heads[i]);
+}
+
+/*
+ * Init idle task and put into queue structure of rq
+ * IMPORTANT: may be called multiple times for a single cpu
+ */
+static inline void sched_queue_init_idle(struct sched_queue *q,
+					 struct task_struct *idle)
+{
+	idle->sq_idx = IDLE_TASK_SCHED_PRIO;
+	INIT_LIST_HEAD(&q->heads[idle->sq_idx]);
+	list_add(&idle->sq_node, &q->heads[idle->sq_idx]);
+	set_bit(idle->sq_idx, q->bitmap);
+}
+
+
+/* water mark related functions*/
 static inline void update_sched_rq_watermark(struct rq *rq)
 {
-	unsigned long watermark = sched_queue_watermark(rq);
+	unsigned long watermark = find_first_bit(rq->queue.bitmap, SCHED_BITS);
 	unsigned long last_wm = rq->watermark;
 	unsigned long i;
 	int cpu;
@@ -6045,19 +6070,6 @@ void dump_cpu_task(int cpu)
 	sched_show_task(cpu_curr(cpu));
 }
 
-/*
- * Init idle task and put into queue structure of rq
- * IMPORTANT: may be called multiple times for a single cpu
- */
-static inline void sched_queue_init_idle(struct sched_queue *q,
-					 struct task_struct *idle)
-{
-	idle->sq_idx = IDLE_TASK_SCHED_PRIO;
-	INIT_LIST_HEAD(&q->heads[idle->sq_idx]);
-	list_add(&idle->sq_node, &q->heads[idle->sq_idx]);
-	set_bit(idle->sq_idx, q->bitmap);
-}
-
 /**
  * init_idle - set up an idle thread for a given CPU
  * @idle: task in question
@@ -6677,6 +6689,7 @@ void __init sched_init(void)
 	struct rq *rq;
 
 	printk(KERN_INFO ALT_SCHED_VERSION_MSG);
+	sched_imp_init();
 
 	wait_bit_init();
 
@@ -6695,7 +6708,7 @@ void __init sched_init(void)
 	for_each_possible_cpu(i) {
 		rq = cpu_rq(i);
 
-		sched_queue_init(rq);
+		sched_queue_init(&rq->queue);
 		rq->watermark = IDLE_WM;
 		rq->skip = NULL;
 
diff --git a/kernel/sched/bmq.h b/kernel/sched/bmq.h
index f5bd651a7666..7858ac1185ce 100644
--- a/kernel/sched/bmq.h
+++ b/kernel/sched/bmq.h
@@ -62,26 +62,13 @@ static inline void time_slice_expired(struct task_struct *p, struct rq *rq)
 	}
 }
 
+static inline void sched_imp_init(void) {}
+
 inline int task_running_nice(struct task_struct *p)
 {
 	return (p->prio + p->boost_prio > DEFAULT_PRIO + MAX_PRIORITY_ADJ);
 }
 
-static inline unsigned long sched_queue_watermark(struct rq *rq)
-{
-	return find_first_bit(rq->queue.bitmap, SCHED_BITS);
-}
-
-static inline void sched_queue_init(struct rq *rq)
-{
-	struct sched_queue *q = &rq->queue;
-	int i;
-
-	bitmap_zero(q->bitmap, SCHED_BITS);
-	for(i = 0; i < SCHED_BITS; i++)
-		INIT_LIST_HEAD(&q->heads[i]);
-}
-
 /*
  * This routine used in bmq scheduler only which assume the idle task in the bmq
  */
diff --git a/kernel/sched/pds.h b/kernel/sched/pds.h
index c29122334bda..64631b2770fe 100644
--- a/kernel/sched/pds.h
+++ b/kernel/sched/pds.h
@@ -14,13 +14,7 @@ static const u64 user_prio2deadline[NICE_WIDTH] = {
 #define SCHED_PRIO_SLOT		(4ULL << 20)
 #define DEFAULT_SCHED_PRIO (MAX_RT_PRIO + 10)
 
-static inline int normal_prio(struct task_struct *p)
-{
-	if (task_has_rt_policy(p))
-		return MAX_RT_PRIO - 1 - p->rt_priority;
-
-	return MAX_RT_PRIO;
-}
+DECLARE_BITMAP(normal_mask, SCHED_BITS);
 
 extern int alt_debug[20];
 
@@ -64,13 +58,49 @@ task_sched_prio_idx(const struct task_struct *p, const struct rq *rq)
 		(task_sched_prio_normal(p, rq) + rq->time_edge) % 20;
 }
 
+static inline unsigned long sched_prio2idx(unsigned long idx, struct rq *rq)
+{
+	if (IDLE_TASK_SCHED_PRIO == idx ||
+	    idx < MAX_RT_PRIO)
+		return idx;
+
+	return MAX_RT_PRIO +
+		((idx - MAX_RT_PRIO) + rq->time_edge) % 20;
+}
+
+static inline unsigned long sched_idx2prio(unsigned long idx, struct rq *rq)
+{
+	if (IDLE_TASK_SCHED_PRIO == idx ||
+	    idx < MAX_RT_PRIO)
+		return idx;
+
+	return MAX_RT_PRIO +
+		((idx - MAX_RT_PRIO) + 20 -  rq->time_edge % 20) % 20;
+}
+
+static inline void sched_renew_deadline(struct task_struct *p, const struct rq *rq)
+{
+	if (p->prio >= MAX_RT_PRIO)
+		p->deadline = rq->clock +
+			SCHED_PRIO_SLOT * (p->static_prio - MAX_RT_PRIO + 1);
+}
+
+/*
+ * Common interfaces
+ */
+static inline int normal_prio(struct task_struct *p)
+{
+	if (task_has_rt_policy(p))
+		return MAX_RT_PRIO - 1 - p->rt_priority;
+
+	return MAX_RT_PRIO;
+}
+
 int task_running_nice(struct task_struct *p)
 {
 	return task_sched_prio(p, task_rq(p)) > DEFAULT_SCHED_PRIO;
 }
 
-DECLARE_BITMAP(normal_mask, SCHED_BITS);
-
 static inline void sched_shift_normal_bitmap(unsigned long *mask, unsigned int shift)
 {
 	DECLARE_BITMAP(normal, SCHED_BITS);
@@ -116,13 +146,6 @@ static inline void update_rq_time_edge(struct rq *rq)
 	}
 }
 
-static inline void sched_renew_deadline(struct task_struct *p, const struct rq *rq)
-{
-	if (p->prio >= MAX_RT_PRIO)
-		p->deadline = rq->clock +
-			SCHED_PRIO_SLOT * (p->static_prio - MAX_RT_PRIO + 1);
-}
-
 static inline void requeue_task(struct task_struct *p, struct rq *rq);
 
 static inline void time_slice_expired(struct task_struct *p, struct rq *rq)
@@ -134,38 +157,9 @@ static inline void time_slice_expired(struct task_struct *p, struct rq *rq)
 		requeue_task(p, rq);
 }
 
-/*
- * Init the queue structure in rq
- */
-static inline void sched_queue_init(struct rq *rq)
+static inline void sched_imp_init(void)
 {
-	struct sched_queue *q = &rq->queue;
-	int i;
-
 	bitmap_set(normal_mask, MAX_RT_PRIO, 20);
-	bitmap_zero(q->bitmap, SCHED_BITS);
-	for(i = 0; i < SCHED_BITS; i++)
-		INIT_LIST_HEAD(&q->heads[i]);
-}
-
-static inline unsigned long sched_prio2idx(unsigned long idx, struct rq *rq)
-{
-	if (IDLE_TASK_SCHED_PRIO == idx ||
-	    idx < MAX_RT_PRIO)
-		return idx;
-
-	return MAX_RT_PRIO +
-		((idx - MAX_RT_PRIO) + rq->time_edge) % 20;
-}
-
-static inline unsigned long sched_idx2prio(unsigned long idx, struct rq *rq)
-{
-	if (IDLE_TASK_SCHED_PRIO == idx ||
-	    idx < MAX_RT_PRIO)
-		return idx;
-
-	return MAX_RT_PRIO +
-		((idx - MAX_RT_PRIO) + 20 -  rq->time_edge % 20) % 20;
 }
 
 /*
@@ -196,11 +190,6 @@ sched_rq_next_task(struct task_struct *p, struct rq *rq)
 	return list_next_entry(p, sq_node);
 }
 
-static inline unsigned long sched_queue_watermark(struct rq *rq)
-{
-	return find_first_bit(rq->queue.bitmap, SCHED_BITS);
-}
-
 #define __SCHED_DEQUEUE_TASK(p, rq, flags, func)		\
 	psi_dequeue(p, flags & DEQUEUE_SLEEP);			\
 	sched_info_dequeued(rq, p);				\
-- 
2.33.1.711.g9d530dc002

