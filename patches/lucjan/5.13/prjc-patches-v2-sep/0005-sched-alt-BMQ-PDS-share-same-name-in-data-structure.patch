From e26550a7f0b17733c22fb7931367b920ef236bfd Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Mon, 17 May 2021 13:48:11 +0000
Subject: [PATCH 05/30] sched/alt: BMQ&PDS share same name in data structure

sq_idx and sq_node are shared in task_struct.
queue is shared in rq.
---
 include/linux/sched.h    |  6 ++---
 init/init_task.c         |  5 ++--
 kernel/sched/alt_sched.h | 10 +++++---
 kernel/sched/bmq.h       |  5 ----
 kernel/sched/bmq_imp.h   | 54 ++++++++++++++++++++--------------------
 kernel/sched/pds.h       |  5 ----
 6 files changed, 37 insertions(+), 48 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 91f32b48a839..35f7cfe6539a 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -715,15 +715,13 @@ struct task_struct {
 #ifdef CONFIG_SCHED_ALT
 	u64				last_ran;
 	s64				time_slice;
+	int				sq_idx;
+	struct list_head		sq_node;
 #ifdef CONFIG_SCHED_BMQ
 	int				boost_prio;
-	int				bmq_idx;
-	struct list_head		bmq_node;
 #endif /* CONFIG_SCHED_BMQ */
 #ifdef CONFIG_SCHED_PDS
 	u64				deadline;
-	int				sq_idx;
-	struct list_head		sq_node;
 #endif /* CONFIG_SCHED_PDS */
 	/* sched_clock time spent running */
 	u64				sched_time;
diff --git a/init/init_task.c b/init/init_task.c
index 79c14fb5973c..89f1e6ace69a 100644
--- a/init/init_task.c
+++ b/init/init_task.c
@@ -99,14 +99,13 @@ struct task_struct init_task
 		.fn = do_no_restart_syscall,
 	},
 #ifdef CONFIG_SCHED_ALT
+	.sq_node	= LIST_HEAD_INIT(init_task.sq_node),
 #ifdef CONFIG_SCHED_BMQ
 	.boost_prio	= 0,
-	.bmq_idx	= 15,
-	.bmq_node	= LIST_HEAD_INIT(init_task.bmq_node),
+	.sq_idx		= 15,
 #endif
 #ifdef CONFIG_SCHED_PDS
 	.deadline	= 0,
-	.sq_node	= LIST_HEAD_INIT(init_task.sq_node),
 #endif
 	.time_slice	= HZ,
 #else
diff --git a/kernel/sched/alt_sched.h b/kernel/sched/alt_sched.h
index cfb4669dfbbf..21f359102fbc 100644
--- a/kernel/sched/alt_sched.h
+++ b/kernel/sched/alt_sched.h
@@ -131,6 +131,11 @@ static inline int task_on_rq_migrating(struct task_struct *p)
 #define WF_MIGRATED	0x04		/* internal use, task got migrated */
 #define WF_ON_CPU	0x08		/* Wakee is on_rq */
 
+struct sched_queue {
+	DECLARE_BITMAP(bitmap, SCHED_BITS);
+	struct list_head heads[SCHED_BITS];
+};
+
 /*
  * This is the main, per-CPU runqueue data structure.
  * This data should only be modified by the local cpu.
@@ -143,11 +148,8 @@ struct rq {
 	struct task_struct *idle, *stop, *skip;
 	struct mm_struct *prev_mm;
 
-#ifdef CONFIG_SCHED_BMQ
-	struct bmq queue;
-#endif
-#ifdef CONFIG_SCHED_PDS
 	struct sched_queue	queue;
+#ifdef CONFIG_SCHED_PDS
 	u64			time_edge;
 #endif
 	unsigned long watermark;
diff --git a/kernel/sched/bmq.h b/kernel/sched/bmq.h
index aba3c98759f8..7f83b7c42619 100644
--- a/kernel/sched/bmq.h
+++ b/kernel/sched/bmq.h
@@ -6,9 +6,4 @@
 #define SCHED_BITS	(MAX_RT_PRIO + NICE_WIDTH / 2 + MAX_PRIORITY_ADJ + 1)
 #define IDLE_TASK_SCHED_PRIO	(SCHED_BITS - 1)
 
-struct bmq {
-	DECLARE_BITMAP(bitmap, SCHED_BITS);
-	struct list_head heads[SCHED_BITS];
-};
-
 #endif
diff --git a/kernel/sched/bmq_imp.h b/kernel/sched/bmq_imp.h
index 7c71f1141d00..f6bd3421b95c 100644
--- a/kernel/sched/bmq_imp.h
+++ b/kernel/sched/bmq_imp.h
@@ -67,8 +67,6 @@ inline int task_running_nice(struct task_struct *p)
 	return (p->prio + p->boost_prio > DEFAULT_PRIO + MAX_PRIORITY_ADJ);
 }
 
-static inline void update_task_priodl(struct task_struct *p) {}
-
 static inline unsigned long sched_queue_watermark(struct rq *rq)
 {
 	return find_first_bit(rq->queue.bitmap, SCHED_BITS);
@@ -76,7 +74,7 @@ static inline unsigned long sched_queue_watermark(struct rq *rq)
 
 static inline void sched_queue_init(struct rq *rq)
 {
-	struct bmq *q = &rq->queue;
+	struct sched_queue *q = &rq->queue;
 	int i;
 
 	bitmap_zero(q->bitmap, SCHED_BITS);
@@ -86,12 +84,12 @@ static inline void sched_queue_init(struct rq *rq)
 
 static inline void sched_queue_init_idle(struct rq *rq, struct task_struct *idle)
 {
-	struct bmq *q = &rq->queue;
+	struct sched_queue *q = &rq->queue;
 
-	idle->bmq_idx = IDLE_TASK_SCHED_PRIO;
-	INIT_LIST_HEAD(&q->heads[idle->bmq_idx]);
-	list_add(&idle->bmq_node, &q->heads[idle->bmq_idx]);
-	set_bit(idle->bmq_idx, q->bitmap);
+	idle->sq_idx = IDLE_TASK_SCHED_PRIO;
+	INIT_LIST_HEAD(&q->heads[idle->sq_idx]);
+	list_add(&idle->sq_node, &q->heads[idle->sq_idx]);
+	set_bit(idle->sq_idx, q->bitmap);
 }
 
 /*
@@ -102,32 +100,32 @@ static inline struct task_struct *sched_rq_first_task(struct rq *rq)
 	unsigned long idx = find_first_bit(rq->queue.bitmap, SCHED_BITS);
 	const struct list_head *head = &rq->queue.heads[idx];
 
-	return list_first_entry(head, struct task_struct, bmq_node);
+	return list_first_entry(head, struct task_struct, sq_node);
 }
 
 static inline struct task_struct *
 sched_rq_next_task(struct task_struct *p, struct rq *rq)
 {
-	unsigned long idx = p->bmq_idx;
+	unsigned long idx = p->sq_idx;
 	struct list_head *head = &rq->queue.heads[idx];
 
-	if (list_is_last(&p->bmq_node, head)) {
+	if (list_is_last(&p->sq_node, head)) {
 		idx = find_next_bit(rq->queue.bitmap, SCHED_BITS, idx + 1);
 		head = &rq->queue.heads[idx];
 
-		return list_first_entry(head, struct task_struct, bmq_node);
+		return list_first_entry(head, struct task_struct, sq_node);
 	}
 
-	return list_next_entry(p, bmq_node);
+	return list_next_entry(p, sq_node);
 }
 
 #define __SCHED_DEQUEUE_TASK(p, rq, flags, func)	\
 	psi_dequeue(p, flags & DEQUEUE_SLEEP);		\
 	sched_info_dequeued(rq, p);			\
 							\
-	list_del(&p->bmq_node);				\
-	if (list_empty(&rq->queue.heads[p->bmq_idx])) {	\
-		clear_bit(p->bmq_idx, rq->queue.bitmap);\
+	list_del(&p->sq_node);				\
+	if (list_empty(&rq->queue.heads[p->sq_idx])) {	\
+		clear_bit(p->sq_idx, rq->queue.bitmap);\
 		func;					\
 	}
 
@@ -135,28 +133,28 @@ sched_rq_next_task(struct task_struct *p, struct rq *rq)
 	sched_info_queued(rq, p);					\
 	psi_enqueue(p, flags);						\
 									\
-	p->bmq_idx = task_sched_prio(p, rq);				\
-	list_add_tail(&p->bmq_node, &rq->queue.heads[p->bmq_idx]);	\
-	set_bit(p->bmq_idx, rq->queue.bitmap)
+	p->sq_idx = task_sched_prio(p, rq);				\
+	list_add_tail(&p->sq_node, &rq->queue.heads[p->sq_idx]);	\
+	set_bit(p->sq_idx, rq->queue.bitmap)
 
 #define __SCHED_REQUEUE_TASK(p, rq, func)				\
 {									\
 	int idx = task_sched_prio(p, rq);				\
 \
-	list_del(&p->bmq_node);						\
-	list_add_tail(&p->bmq_node, &rq->queue.heads[idx]);		\
-	if (idx != p->bmq_idx) {					\
-		if (list_empty(&rq->queue.heads[p->bmq_idx]))		\
-			clear_bit(p->bmq_idx, rq->queue.bitmap);	\
-		p->bmq_idx = idx;					\
-		set_bit(p->bmq_idx, rq->queue.bitmap);			\
+	list_del(&p->sq_node);						\
+	list_add_tail(&p->sq_node, &rq->queue.heads[idx]);		\
+	if (idx != p->sq_idx) {					\
+		if (list_empty(&rq->queue.heads[p->sq_idx]))		\
+			clear_bit(p->sq_idx, rq->queue.bitmap);	\
+		p->sq_idx = idx;					\
+		set_bit(p->sq_idx, rq->queue.bitmap);			\
 		func;							\
 	}								\
 }
 
 static inline bool sched_task_need_requeue(struct task_struct *p, struct rq *rq)
 {
-	return (task_sched_prio(p, rq) != p->bmq_idx);
+	return (task_sched_prio(p, rq) != p->sq_idx);
 }
 
 static void sched_task_fork(struct task_struct *p, struct rq *rq)
@@ -201,3 +199,5 @@ static void sched_task_deactivate(struct task_struct *p, struct rq *rq)
 	if (rq_switch_time(rq) < boost_threshold(p))
 		boost_task(p);
 }
+
+static inline void update_rq_time_edge(struct rq *rq) {}
diff --git a/kernel/sched/pds.h b/kernel/sched/pds.h
index 3afc6fd7a27f..623908cf4380 100644
--- a/kernel/sched/pds.h
+++ b/kernel/sched/pds.h
@@ -6,9 +6,4 @@
 #define SCHED_BITS	(MAX_RT_PRIO + NICE_WIDTH / 2 + 1)
 #define IDLE_TASK_SCHED_PRIO	(SCHED_BITS - 1)
 
-struct sched_queue {
-	DECLARE_BITMAP(bitmap, SCHED_BITS);
-	struct list_head heads[SCHED_BITS];
-};
-
 #endif
-- 
2.32.0.93.g670b81a890

